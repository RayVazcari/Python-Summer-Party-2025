{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 7: Celebrity Product Drops Sales Performance Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You are a Product Analyst working on Nike's marketing performance team. Your team wants to evaluate the effectiveness of celebrity product collaborations by analyzing sales data. You will investigate the performance of celebrity product drops to inform future marketing strategies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nimport numpy as np\n\nfct_sales_data = [\n  {\n    \"sale_id\": 1,\n    \"sale_date\": \"2025-01-10\",\n    \"product_id\": 901,\n    \"sale_amount\": null,\n    \"celebrity_id\": 101\n  },\n  {\n    \"sale_id\": 2,\n    \"sale_date\": \"2025-01-15\",\n    \"product_id\": 901,\n    \"sale_amount\": 1500,\n    \"celebrity_id\": 101\n  },\n  {\n    \"sale_id\": 3,\n    \"sale_date\": \"2025-02-03\",\n    \"product_id\": 902,\n    \"sale_amount\": 2000.5,\n    \"celebrity_id\": 102\n  },\n  {\n    \"sale_id\": 4,\n    \"sale_date\": \"2025-03-12\",\n    \"product_id\": 903,\n    \"sale_amount\": 2500.75,\n    \"celebrity_id\": 103\n  },\n  {\n    \"sale_id\": 5,\n    \"sale_date\": \"2025-03-20\",\n    \"product_id\": 904,\n    \"sale_amount\": null,\n    \"celebrity_id\": 104\n  },\n  {\n    \"sale_id\": 6,\n    \"sale_date\": \"2025-02-28\",\n    \"product_id\": 901,\n    \"sale_amount\": 1000,\n    \"celebrity_id\": 101\n  },\n  {\n    \"sale_id\": 7,\n    \"sale_date\": \"2025-03-25\",\n    \"product_id\": 902,\n    \"sale_amount\": 300,\n    \"celebrity_id\": 102\n  },\n  {\n    \"sale_id\": 8,\n    \"sale_date\": \"2025-03-30\",\n    \"product_id\": 905,\n    \"sale_amount\": 1800,\n    \"celebrity_id\": 105\n  },\n  {\n    \"sale_id\": 9,\n    \"sale_date\": \"2025-01-20\",\n    \"product_id\": 903,\n    \"sale_amount\": 1200,\n    \"celebrity_id\": 103\n  },\n  {\n    \"sale_id\": 10,\n    \"sale_date\": \"2025-02-05\",\n    \"product_id\": 906,\n    \"sale_amount\": 500,\n    \"celebrity_id\": 106\n  },\n  {\n    \"sale_id\": 11,\n    \"sale_date\": \"2025-03-01\",\n    \"product_id\": 907,\n    \"sale_amount\": 2200,\n    \"celebrity_id\": 107\n  },\n  {\n    \"sale_id\": 12,\n    \"sale_date\": \"2025-02-15\",\n    \"product_id\": 908,\n    \"sale_amount\": 1300,\n    \"celebrity_id\": 101\n  },\n  {\n    \"sale_id\": 13,\n    \"sale_date\": \"2025-03-15\",\n    \"product_id\": 909,\n    \"sale_amount\": null,\n    \"celebrity_id\": 102\n  },\n  {\n    \"sale_id\": 14,\n    \"sale_date\": \"2025-01-25\",\n    \"product_id\": 910,\n    \"sale_amount\": 900,\n    \"celebrity_id\": 108\n  },\n  {\n    \"sale_id\": 15,\n    \"sale_date\": \"2025-02-20\",\n    \"product_id\": 905,\n    \"sale_amount\": 700,\n    \"celebrity_id\": 105\n  },\n  {\n    \"sale_id\": 16,\n    \"sale_date\": \"2025-03-28\",\n    \"product_id\": 902,\n    \"sale_amount\": 1500,\n    \"celebrity_id\": 102\n  },\n  {\n    \"sale_id\": 17,\n    \"sale_date\": \"2024-11-15\",\n    \"product_id\": 901,\n    \"sale_amount\": 800,\n    \"celebrity_id\": 101\n  },\n  {\n    \"sale_id\": 18,\n    \"sale_date\": \"2024-07-30\",\n    \"product_id\": 902,\n    \"sale_amount\": 1000,\n    \"celebrity_id\": 102\n  },\n  {\n    \"sale_id\": 19,\n    \"sale_date\": \"2025-04-10\",\n    \"product_id\": 905,\n    \"sale_amount\": 2000,\n    \"celebrity_id\": 105\n  },\n  {\n    \"sale_id\": 20,\n    \"sale_date\": \"2024-09-05\",\n    \"product_id\": 903,\n    \"sale_amount\": 1100,\n    \"celebrity_id\": 103\n  }\n]\nfct_sales = pd.DataFrame(fct_sales_data)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1\n\nFor Q1 2025 (January 1st through March 31st, 2025), can you identify all records of celebrity collaborations from the sales data where the sale_amount is missing? This will help us flag incomplete records that could impact the analysis of Nike's product performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: fct_sales\n# Please print your final result or dataframe\n\n# Load the sales data\nq1_fct_sales_df = fct_sales.copy()\nprint(q1_fct_sales_df)\nprint(\"=\" * 150)\nprint()\n\n# Sanity checks and initial exploration\nprint(q1_fct_sales_df.info())\nprint(\"=\" * 150)\nprint()\n\n# First we need to change the sale_date column to datetime format\nq1_fct_sales_df[\"sale_date\"] = pd.to_datetime(q1_fct_sales_df[\"sale_date\"], format=\"%Y-%m-%d\")\nprint(q1_fct_sales_df.info())\nprint()\nprint(q1_fct_sales_df.head())\nprint(\"=\" * 150)\nprint()\n\n# Now we sort the dataframe by year and month in ascending order for better readability\nq1_fct_sales_df = q1_fct_sales_df.sort_values(['sale_date'], ascending=True).reset_index(drop=True)\nprint(q1_fct_sales_df)\nprint(\"=\" * 150)\nprint()\n\n# Now we filter the dataframe for Q1 2025 which is January 1st through March 31st, 2025\nQ1_df = q1_fct_sales_df[(q1_fct_sales_df['sale_date'] >= '2025-01-01') & (q1_fct_sales_df['sale_date'] <= '2025-03-31')]\nprint(Q1_df)\nprint(\"=\" * 150)\nprint()\n\n# We can see there are 3 records with missing sale_amount in Q1 2025\n #Now we select and filter only those records with missing sale_amount\nQ1_df = Q1_df[Q1_df['sale_amount'].isnull()]\nprint(Q1_df)\nprint(\"=\" * 150)\nprint()\n\n# Question 1 Answer: There are 3 records with missing sale_amount in Q1 2025.'\nprint(\"Question 1 Answer: There are\", len(Q1_df), \"records with missing sale_amount in Q1 2025.\");\nprint(\"These records are:\");\nprint(Q1_df)\nprint(\"=\" * 150)\nprint()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2\n\nFor Q1 2025 (January 1st through March 31st, 2025), can you list the unique combinations of celebrity_id and product_id from the sales table? This will ensure that each collaboration is accurately accounted for in the analysis of Nike's marketing performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: fct_sales\n# Please print your final result or dataframe\n\n# Load the sales data\nq1_fct_sales_df = fct_sales.copy()\nprint(q1_fct_sales_df)\nprint(\"=\" * 150)\nprint()\n\n# Sanity checks and initial exploration\nprint(q1_fct_sales_df.info())\nprint(\"=\" * 150)\nprint()\n\n# First we need to change the sale_date column to datetime format\nq1_fct_sales_df[\"sale_date\"] = pd.to_datetime(q1_fct_sales_df[\"sale_date\"], format=\"%Y-%m-%d\")\nprint(q1_fct_sales_df.info())\nprint()\nprint(q1_fct_sales_df.head())\nprint(\"=\" * 150)\nprint()\n\n# Now we sort the dataframe by year and month in ascending order for better readability\nq1_fct_sales_df = q1_fct_sales_df.sort_values(['sale_date'], ascending=True).reset_index(drop=True)\nprint(q1_fct_sales_df)\nprint(\"=\" * 150)\nprint()\n\n# Now we filter the dataframe for Q1 2025 which is January 1st through March 31st, 2025\nQ1_df = q1_fct_sales_df[(q1_fct_sales_df['sale_date'] >= '2025-01-01') & (q1_fct_sales_df['sale_date'] <= '2025-03-31')]\nprint(Q1_df)\nprint(\"=\" * 150)\nprint()\n\n# We can see there are 3 records with missing sale_amount in Q1 2025\n #Now we select and filter only those records with missing sale_amount\nQ1_missing_df = Q1_df[Q1_df['sale_amount'].isnull()]\nprint(Q1_missing_df)\nprint(\"=\" * 150)\nprint()\n\n# Question 1 Answer: There are 3 records with missing sale_amount in Q1 2025.'\nprint(\"Question 1 Answer: There are\", len(Q1_missing_df), \"records with missing sale_amount in Q1 2025.\");\nprint(\"These records are:\");\nprint(Q1_missing_df)\nprint(\"=\" * 150)\nprint()\n\n\n# ==============================================================================\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n# ==============================================================================\n\n# Printing Q1 dataframe and its info for verification\nprint(Q1_df)\nprint(Q1_df.info())\nprint(\"=\" * 150)\nprint()\n\n# We can use groupby to get the unique combinations of celebrity_id and product_id\nQ1_unique_combinations = Q1_df.groupby(['celebrity_id', 'product_id']).size().reset_index(name='count')\nprint(Q1_unique_combinations)\n\n\n# Question 2 Answer: The following table shows the unique combinations of celebrity_id and product_id in Q1 2025.\nprint(\"Question 2 Answer: The following table shows the unique combinations of celebrity_id and product_id in Q1 2025.\")\nprint(Q1_unique_combinations)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3\n\nFor Q1 2025 (January 1st through March 31st, 2025), can you rank the unique celebrity collaborations based on their total sales amounts and list the top 3 collaborations in descending order? This will help recommend the most successful partnerships for Nike's future product drop strategies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: fct_sales\n# Please print your final result or dataframe\n\n# Question 1\n\n# Load the sales data\nq1_fct_sales_df = fct_sales.copy()\nprint(q1_fct_sales_df)\nprint(\"=\" * 150)\nprint()\n\n# Sanity checks and initial exploration\nprint(q1_fct_sales_df.info())\nprint(\"=\" * 150)\nprint()\n\n# First we need to change the sale_date column to datetime format\nq1_fct_sales_df[\"sale_date\"] = pd.to_datetime(q1_fct_sales_df[\"sale_date\"], format=\"%Y-%m-%d\")\nprint(q1_fct_sales_df.info())\nprint()\nprint(q1_fct_sales_df.head())\nprint(\"=\" * 150)\nprint()\n\n# Now we sort the dataframe by year and month in ascending order for better readability\nq1_fct_sales_df = q1_fct_sales_df.sort_values(['sale_date'], ascending=True).reset_index(drop=True)\nprint(q1_fct_sales_df)\nprint(\"=\" * 150)\nprint()\n\n# Now we filter the dataframe for Q1 2025 which is January 1st through March 31st, 2025\nQ1_df = q1_fct_sales_df[(q1_fct_sales_df['sale_date'] >= '2025-01-01') & (q1_fct_sales_df['sale_date'] <= '2025-03-31')]\nprint(Q1_df)\nprint(\"=\" * 150)\nprint()\n\n# We can see there are 3 records with missing sale_amount in Q1 2025\n #Now we select and filter only those records with missing sale_amount\nQ1_missing_df = Q1_df[Q1_df['sale_amount'].isnull()]\nprint(Q1_missing_df)\nprint(\"=\" * 150)\nprint()\n\n# Question 1 Answer: There are 3 records with missing sale_amount in Q1 2025.'\nprint(\"Question 1 Answer: There are\", len(Q1_missing_df), \"records with missing sale_amount in Q1 2025.\");\nprint(\"These records are:\");\nprint(Q1_missing_df)\nprint(\"=\" * 150)\nprint()\n\n\n# ==============================================================================\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n# ==============================================================================\n\n#Question 2\n\n# Printing Q1 dataframe and its info for verification\nprint(Q1_df)\nprint(Q1_df.info())\nprint(\"=\" * 150)\nprint()\n\n# We can use groupby to get the unique combinations of celebrity_id and product_id\nQ1_unique_combinations = Q1_df.groupby(['celebrity_id', 'product_id']).size().reset_index(name='count')\nprint(Q1_unique_combinations)\nprint(\"=\" * 150)\nprint()\n\n# Question 2 Answer: The following table shows the unique combinations of celebrity_id and product_id in Q1 2025.\nprint(\"Question 2 Answer: The following table shows the unique combinations of celebrity_id and product_id in Q1 2025.\")\nprint(Q1_unique_combinations)\nprint(\"=\" * 150)\nprint()\n\n\n# ==============================================================================\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n# ==============================================================================\n\n#Question 3\n\n# Printing Q1 dataframe and its info for verification\nprint(Q1_df)\nprint(Q1_df.info())\nprint(\"=\" * 150)\nprint()\n\n# We can use groupby to get the unique combinations of celebrity_id and product_id\nQ1_sales_collabs = Q1_df.groupby(['celebrity_id', 'product_id']).agg(total_sales_volume = ('sale_amount', 'sum')).sort_values(by=['celebrity_id', 'product_id']).reset_index()\nprint(Q1_sales_collabs)\nprint(\"=\" * 150)\nprint()\n\n# Now we rank the collaborations based on total sales volume in descending order\nQ1_ranked_collabs = Q1_sales_collabs.copy()\nQ1_ranked_collabs = Q1_ranked_collabs.sort_values(by=['total_sales_volume'], ascending=False).reset_index(drop=True)\nprint(Q1_ranked_collabs)\nprint(\"=\" * 150)\nprint()\n\n# We can use .head() to get the top 3 collaborations now that it is ranked\ntop_3_collabs = Q1_ranked_collabs.head(3)\nprint(top_3_collabs)\nprint(\"=\" * 150)\nprint()\n\n# Answer to Question 3: The top 3 celebrity-product collaborations based on total sales volume in Q1 2025 are shown in the table above.\nprint(\"Question 3 Answer: The top 3 collaborations based on total sales volume in Q1 2025 are:\")\nprint(top_3_collabs)\nprint(\"=\" * 150)\nprint()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Made with ❤️ by [Interview Master](https://www.interviewmaster.ai)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3",
      "mimetype": "text/x-python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}