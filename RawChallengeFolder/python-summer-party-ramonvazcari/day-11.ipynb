{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 11: Payment Fraud Risk Detection in Online Transactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You are a data analyst in Stripe's risk management team investigating transaction patterns to identify potential fraud. The team needs to develop a systematic approach to screen transactions for financial risks. Your goal is to create an initial risk assessment methodology using transaction characteristics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nimport numpy as np\n\ndim_risk_flags_data = [\n  {\n    \"risk_level\": \"Low\",\n    \"risk_flag_id\": 1,\n    \"transaction_id\": 2\n  },\n  {\n    \"risk_level\": \"Medium\",\n    \"risk_flag_id\": 2,\n    \"transaction_id\": 7\n  },\n  {\n    \"risk_level\": \"High\",\n    \"risk_flag_id\": 3,\n    \"transaction_id\": 11\n  },\n  {\n    \"risk_level\": \"High\",\n    \"risk_flag_id\": 4,\n    \"transaction_id\": 12\n  },\n  {\n    \"risk_level\": \"High\",\n    \"risk_flag_id\": 5,\n    \"transaction_id\": 13\n  },\n  {\n    \"risk_level\": \"Medium\",\n    \"risk_flag_id\": 6,\n    \"transaction_id\": 14\n  },\n  {\n    \"risk_level\": \"High\",\n    \"risk_flag_id\": 7,\n    \"transaction_id\": 15\n  },\n  {\n    \"risk_level\": \"Low\",\n    \"risk_flag_id\": 8,\n    \"transaction_id\": 1\n  },\n  {\n    \"risk_level\": \"Medium\",\n    \"risk_flag_id\": 9,\n    \"transaction_id\": 6\n  },\n  {\n    \"risk_level\": \"Low\",\n    \"risk_flag_id\": 10,\n    \"transaction_id\": 3\n  }\n]\ndim_risk_flags = pd.DataFrame(dim_risk_flags_data)\n\nfct_transactions_data = [\n  {\n    \"customer_email\": \"alice@gmail.com\",\n    \"transaction_id\": 1,\n    \"transaction_date\": \"2024-10-05\",\n    \"transaction_amount\": 120,\n    \"fraud_detection_score\": 10\n  },\n  {\n    \"customer_email\": \"bob@customdomain.com\",\n    \"transaction_id\": 2,\n    \"transaction_date\": \"2024-10-15\",\n    \"transaction_amount\": 250.5,\n    \"fraud_detection_score\": 20\n  },\n  {\n    \"customer_email\": \"charlie@yahoo.com\",\n    \"transaction_id\": 3,\n    \"transaction_date\": \"2024-10-20\",\n    \"transaction_amount\": 75.25,\n    \"fraud_detection_score\": 15\n  },\n  {\n    \"customer_email\": \"dana@hotmail.com\",\n    \"transaction_id\": 4,\n    \"transaction_date\": \"2024-10-25\",\n    \"transaction_amount\": 100,\n    \"fraud_detection_score\": 30\n  },\n  {\n    \"customer_email\": \"eve@biz.org\",\n    \"transaction_id\": 5,\n    \"transaction_date\": \"2024-10-30\",\n    \"transaction_amount\": 300,\n    \"fraud_detection_score\": 40\n  },\n  {\n    \"customer_email\": \"frank@gmail.com\",\n    \"transaction_id\": 6,\n    \"transaction_date\": \"2024-11-03\",\n    \"transaction_amount\": 150.75,\n    \"fraud_detection_score\": 25\n  },\n  {\n    \"customer_email\": \"grace@outlook.com\",\n    \"transaction_id\": 7,\n    \"transaction_date\": \"2024-11-10\",\n    \"transaction_amount\": null,\n    \"fraud_detection_score\": 50\n  },\n  {\n    \"customer_email\": \"ivan@yahoo.com\",\n    \"transaction_id\": 8,\n    \"transaction_date\": \"2024-11-15\",\n    \"transaction_amount\": 200,\n    \"fraud_detection_score\": 35\n  },\n  {\n    \"customer_email\": \"judy@hotmail.com\",\n    \"transaction_id\": 9,\n    \"transaction_date\": \"2024-11-21\",\n    \"transaction_amount\": 250,\n    \"fraud_detection_score\": 45\n  },\n  {\n    \"customer_email\": \"ken@domain.net\",\n    \"transaction_id\": 10,\n    \"transaction_date\": \"2024-11-29\",\n    \"transaction_amount\": 300,\n    \"fraud_detection_score\": 55\n  },\n  {\n    \"customer_email\": \"laura@riskmail.com\",\n    \"transaction_id\": 11,\n    \"transaction_date\": \"2024-12-02\",\n    \"transaction_amount\": 100,\n    \"fraud_detection_score\": 80\n  },\n  {\n    \"customer_email\": \"mike@securepay.com\",\n    \"transaction_id\": 12,\n    \"transaction_date\": \"2024-12-03\",\n    \"transaction_amount\": 180,\n    \"fraud_detection_score\": 85\n  },\n  {\n    \"customer_email\": \"nina@trusthub.com\",\n    \"transaction_id\": 13,\n    \"transaction_date\": \"2024-12-09\",\n    \"transaction_amount\": 220,\n    \"fraud_detection_score\": 90\n  },\n  {\n    \"customer_email\": \"oscar@fintech.com\",\n    \"transaction_id\": 14,\n    \"transaction_date\": \"2024-12-16\",\n    \"transaction_amount\": 140,\n    \"fraud_detection_score\": 70\n  },\n  {\n    \"customer_email\": \"paula@alertsys.com\",\n    \"transaction_id\": 15,\n    \"transaction_date\": \"2024-12-23\",\n    \"transaction_amount\": 260,\n    \"fraud_detection_score\": 95\n  }\n]\nfct_transactions = pd.DataFrame(fct_transactions_data)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1\n\nHow many transactions in October 2024 have a customer email ending with a domain other than 'gmail.com', 'yahoo.com', or 'hotmail.com'? This metric will help us identify transactions associated with less common email providers that may indicate emerging risk patterns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: fct_transactions, dim_risk_flags\n# Please print your final result or dataframe\n\n# Load the CSV file into a DataFrame and display it\nfct_transactions_df = fct_transactions.copy()\ndim_risk_flags_df = dim_risk_flags.copy()\n\nprint(fct_transactions_df.info())\nprint()\nprint(fct_transactions_df.head())\nprint()\nprint(dim_risk_flags_df.info())\nprint()\nprint(dim_risk_flags_df.head())\nprint()\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 1 of 3\n# How many transactions in October 2024 have a customer email ending with a domain other than 'gmail.com', 'yahoo.com', or 'hotmail.com'? This metric will help us identify transactions associated with less common email providers that may indicate emerging risk patterns.\n\n# First we need to normalize and transform the 'transaction_date' column to datetime format\nfct_transactions_df['transaction_date'] = pd.to_datetime(fct_transactions_df['transaction_date'], format='%Y-%m-%d', errors='coerce')\nprint(\"'transaction_date' after converting to datetime format:\")\nprint(fct_transactions_df.info())\nprint()\n\n# Lets find inconsistencies in 'customer_email'\nprint(fct_transactions_df['customer_email'].unique())\nprint()\nprint(\"=\" * 150)\n\n# 'customer_email' is clean, no inconsistencies\n# Now we will have to group the data by transaction_date\nfct_oct_transactions_df = fct_transactions_df[(fct_transactions_df['transaction_date'] >= '2024-10-01') & (fct_transactions_df['transaction_date'] < '2024-11-01')]\nprint(fct_oct_transactions_df.info()) \nprint(fct_oct_transactions_df.head())\nprint()\nprint(\"=\" * 150)\n\n# We will now find transactions with a domain other than 'gmail.com', 'yahoo.com', or 'hotmail.com'\n# To do that we need to define a tuple of valid domains\nvalid_domains = ('@gmail.com', '@yahoo.com', '@hotmail.com')\n\n# Then we will find the transactions using '~' as negation and the 'str.endswith' method\nfct_oct_trans_val_email_df = fct_oct_transactions_df[~fct_oct_transactions_df['customer_email'].str.endswith(valid_domains, na=False)]\nprint(fct_oct_trans_val_email_df)\nprint()\nprint(\"=\" * 150)\n\n# Now we display the count of transactions by customer_email\nprint(\"There are only\", fct_oct_trans_val_email_df.shape[0], \"transactions with with a domain other than 'gmail.com', 'yahoo.com', or 'hotmail.com'\")\nprint()\nprint(\"=\" * 150)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2\n\nFor transactions occurring in November 2024, what is the average transaction amount, using 0 as a default for any missing values? This calculation will help us detect abnormal transaction amounts that could be related to fraudulent activity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: fct_transactions, dim_risk_flags\n# Please print your final result or dataframe\n\n# Load the CSV file into a DataFrame and display it\nfct_transactions_df = fct_transactions.copy()\ndim_risk_flags_df = dim_risk_flags.copy()\n\nprint(fct_transactions_df.info())\nprint()\nprint(fct_transactions_df.head())\nprint()\nprint(dim_risk_flags_df.info())\nprint()\nprint(dim_risk_flags_df.head())\nprint()\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 1 of 3\n# How many transactions in October 2024 have a customer email ending with a domain other than 'gmail.com', 'yahoo.com', or 'hotmail.com'? This metric will help us identify transactions associated with less common email providers that may indicate emerging risk patterns.\n\n# First we need to normalize and transform the 'transaction_date' column to datetime format\nfct_transactions_df['transaction_date'] = pd.to_datetime(fct_transactions_df['transaction_date'], format='%Y-%m-%d', errors='coerce')\nprint(\"'transaction_date' after converting to datetime format:\")\nprint(fct_transactions_df.info())\nprint()\n\n# Lets find inconsistencies in 'customer_email'\nprint(fct_transactions_df['customer_email'].unique())\nprint()\nprint(\"=\" * 150)\n\n# 'customer_email' is clean, no inconsistencies\n# Now we will have to group the data by transaction_date\nfct_oct_transactions_df = fct_transactions_df[(fct_transactions_df['transaction_date'] >= '2024-10-01') & (fct_transactions_df['transaction_date'] < '2024-11-01')]\nprint(fct_oct_transactions_df.info()) \nprint(fct_oct_transactions_df.head())\nprint()\nprint(\"=\" * 150)\n\n# We will now find transactions with a domain other than 'gmail.com', 'yahoo.com', or 'hotmail.com'\n# To do that we need to define a tuple of valid domains\nvalid_domains = ('@gmail.com', '@yahoo.com', '@hotmail.com')\n\n# Then we will find the transactions using '~' as negation and the 'str.endswith' method\nfct_oct_trans_val_email_df = fct_oct_transactions_df[~fct_oct_transactions_df['customer_email'].str.endswith(valid_domains, na=False)]\nprint(fct_oct_trans_val_email_df)\nprint()\nprint(\"=\" * 150)\n\n# Now we display the count of transactions by customer_email\nprint(\"There are only\", fct_oct_trans_val_email_df.shape[0], \"transactions with with a domain other than 'gmail.com', 'yahoo.com', or 'hotmail.com'\")\nprint()\nprint(\"=\" * 150)\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 2 of 3\n# For transactions occurring in November 2024, what is the average transaction amount, using 0 as a default for any missing values? This calculation will help us detect abnormal transaction amounts that could be related to fraudulent activity.\n\n# We will need to re-filter the date to include november 2024\nfct_nov_transactions_df = fct_transactions_df[(fct_transactions_df['transaction_date'] >= '2024-11-01') & (fct_transactions_df['transaction_date'] < '2024-12-01')]\nprint(fct_nov_transactions_df.info()) \nprint()\nprint(fct_nov_transactions_df.head())\nprint()\nprint(\"=\" * 150)\n\n# We can see that there is one null value for transaction_ammount so we will be replacinging it with 0\nfct_nov_transactions_df = fct_nov_transactions_df.copy()\nfct_nov_transactions_df['transaction_amount'] = pd.to_numeric(fct_nov_transactions_df['transaction_amount'], errors='coerce').fillna(0)\nprint(fct_nov_transactions_df.info())\nprint()\nprint(\"=\" * 150)\n\n# Now that we got rid of the null values we can proceed and calculate the average transaction amount for the whole month\nfct_nov_avg_transaction_df = fct_nov_transactions_df['transaction_amount'].mean()\nprint(\"The average transaction amount for the whole month of November 2024 is:\", fct_nov_avg_transaction_df)\nprint()\nprint(\"=\" * 150)\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 3 of 3\n# Among transactions flagged as 'High' risk in December 2024, which day of the week recorded the highest number of such transactions? This analysis is intended to pinpoint specific days with concentrated high-risk activity and support the development of our preliminary fraud detection score.\n\n# We start again by filtering for transactions in December 2024\nfct_dec_transactions_df = fct_transactions_df[(fct_transactions_df['transaction_date'] >= '2024-12-01') & (fct_transactions_df['transaction_date'] < '2025-01-01')]\nprint(fct_dec_transactions_df.info()) \nprint(fct_dec_transactions_df.head())\nprint()\nprint(\"=\" * 150)\n\n# Then we will need to append the 'dim_risk_flags' DataFrame to the 'fct_transactions' DataFrame\nfct_dec_tran_risk_df = pd.merge(fct_dec_transactions_df, dim_risk_flags_df, how='left', on='transaction_id')\nprint(fct_dec_tran_risk_df.info())\nprint(fct_dec_tran_risk_df)\nprint()\nprint(\"=\" * 150)\n\n# Filter for high risk transactions\ndec_high_risk = fct_dec_tran_risk_df[(fct_dec_tran_risk_df['risk_level'] == 'High')].copy()\nprint(dec_high_risk.info())\nprint()\nprint(\"=\" * 150)\n\n# Add weekday column\ndec_high_risk['day_of_week'] = dec_high_risk['transaction_date'].dt.day_name()\nprint(dec_high_risk.info())\nprint()\nprint(dec_high_risk.head())\nprint()\nprint(\"=\" * 150)\n\n# Count by weekday\nweekday_counts = dec_high_risk.groupby('day_of_week').size().reset_index(name='transaction_count')\n\n# Find the max\nmax_day = weekday_counts.sort_values('transaction_count', ascending=False).head(1)\n\n# Answer to question 3 \nprint(\"\\nWeekdays with high-risk activity in Dec 2024:\")\nprint(weekday_counts)\nprint(\"\\nDay with highest high-risk activity in Dec 2024:\")\nprint(max_day)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3\n\nAmong transactions flagged as 'High' risk in December 2024, which day of the week recorded the highest number of such transactions? This analysis is intended to pinpoint specific days with concentrated high-risk activity and support the development of our preliminary fraud detection score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "fct_transactions_df = fct_transactions.copy()\ndim_risk_flags_df = dim_risk_flags.copy()\n\nprint(fct_transactions_df.info())\nprint()\nprint(fct_transactions_df.head())\nprint()\nprint(dim_risk_flags_df.info())\nprint()\nprint(dim_risk_flags_df.head())\nprint()\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 1 of 3\n# How many transactions in October 2024 have a customer email ending with a domain other than 'gmail.com', 'yahoo.com', or 'hotmail.com'? This metric will help us identify transactions associated with less common email providers that may indicate emerging risk patterns.\n\n# First we need to normalize and transform the 'transaction_date' column to datetime format\nfct_transactions_df['transaction_date'] = pd.to_datetime(fct_transactions_df['transaction_date'], format='%Y-%m-%d', errors='coerce')\nprint(\"'transaction_date' after converting to datetime format:\")\nprint(fct_transactions_df.info())\nprint()\n\n# Lets find inconsistencies in 'customer_email'\nprint(fct_transactions_df['customer_email'].unique())\nprint()\nprint(\"=\" * 150)\n\n# 'customer_email' is clean, no inconsistencies\n# Now we will have to group the data by transaction_date\nfct_oct_transactions_df = fct_transactions_df[(fct_transactions_df['transaction_date'] >= '2024-10-01') & (fct_transactions_df['transaction_date'] < '2024-11-01')]\nprint(fct_oct_transactions_df.info()) \nprint(fct_oct_transactions_df.head())\nprint()\nprint(\"=\" * 150)\n\n# We will now find transactions with a domain other than 'gmail.com', 'yahoo.com', or 'hotmail.com'\n# To do that we need to define a tuple of valid domains\nvalid_domains = ('@gmail.com', '@yahoo.com', '@hotmail.com')\n\n# Then we will find the transactions using '~' as negation and the 'str.endswith' method\nfct_oct_trans_val_email_df = fct_oct_transactions_df[~fct_oct_transactions_df['customer_email'].str.endswith(valid_domains, na=False)]\nprint(fct_oct_trans_val_email_df)\nprint()\nprint(\"=\" * 150)\n\n# Now we display the count of transactions by customer_email\nprint(\"There are only\", fct_oct_trans_val_email_df.shape[0], \"transactions with with a domain other than 'gmail.com', 'yahoo.com', or 'hotmail.com'\")\nprint()\nprint(\"=\" * 150)\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 2 of 3\n# For transactions occurring in November 2024, what is the average transaction amount, using 0 as a default for any missing values? This calculation will help us detect abnormal transaction amounts that could be related to fraudulent activity.\n\n# We will need to re-filter the date to include november 2024\nfct_nov_transactions_df = fct_transactions_df[(fct_transactions_df['transaction_date'] >= '2024-11-01') & (fct_transactions_df['transaction_date'] < '2024-12-01')]\nprint(fct_nov_transactions_df.info()) \nprint()\nprint(fct_nov_transactions_df.head())\nprint()\nprint(\"=\" * 150)\n\n# We can see that there is one null value for transaction_ammount so we will be replacinging it with 0\nfct_nov_transactions_df = fct_nov_transactions_df.copy()\nfct_nov_transactions_df['transaction_amount'] = pd.to_numeric(fct_nov_transactions_df['transaction_amount'], errors='coerce').fillna(0)\nprint(fct_nov_transactions_df.info())\nprint()\nprint(\"=\" * 150)\n\n# Now that we got rid of the null values we can proceed and calculate the average transaction amount for the whole month\nfct_nov_avg_transaction_df = fct_nov_transactions_df['transaction_amount'].mean()\nprint(\"The average transaction amount for the whole month of November 2024 is:\", fct_nov_avg_transaction_df)\nprint()\nprint(\"=\" * 150)\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 3 of 3\n# Among transactions flagged as 'High' risk in December 2024, which day of the week recorded the highest number of such transactions? This analysis is intended to pinpoint specific days with concentrated high-risk activity and support the development of our preliminary fraud detection score.\n\n# We start again by filtering for transactions in December 2024\nfct_dec_transactions_df = fct_transactions_df[(fct_transactions_df['transaction_date'] >= '2024-12-01') & (fct_transactions_df['transaction_date'] < '2025-01-01')]\nprint(fct_dec_transactions_df.info()) \nprint(fct_dec_transactions_df.head())\nprint()\nprint(\"=\" * 150)\n\n# Then we will need to append the 'dim_risk_flags' DataFrame to the 'fct_transactions' DataFrame\nfct_dec_tran_risk_df = pd.merge(fct_dec_transactions_df, dim_risk_flags_df, how='left', on='transaction_id')\nprint(fct_dec_tran_risk_df.info())\nprint(fct_dec_tran_risk_df)\nprint()\nprint(\"=\" * 150)\n\n# Filter for high risk transactions\ndec_high_risk = fct_dec_tran_risk_df[(fct_dec_tran_risk_df['risk_level'] == 'High')].copy()\nprint(dec_high_risk.info())\nprint()\nprint(\"=\" * 150)\n\n# Add weekday column\ndec_high_risk['day_of_week'] = dec_high_risk['transaction_date'].dt.day_name()\nprint(dec_high_risk.info())\nprint()\nprint(dec_high_risk.head())\nprint()\nprint(\"=\" * 150)\n\n# Count by weekday\nweekday_counts = dec_high_risk.groupby('day_of_week').size().reset_index(name='transaction_count')\n\n# Find the max\nmax_day = weekday_counts.sort_values('transaction_count', ascending=False).head(1)\n\n# Answer to question 3 \nprint(\"\\nWeekdays with high-risk activity in Dec 2024:\")\nprint(weekday_counts)\nprint(\"\\nDay with highest high-risk activity in Dec 2024:\")\nprint(max_day)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Made with ❤️ by [Interview Master](https://www.interviewmaster.ai)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3",
      "mimetype": "text/x-python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}