{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 13: New Milkshake Flavor Selection for Launch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You are a Product Analyst working with the Shake Shack R&D team to evaluate customer ratings for experimental milkshake flavors. Your team has collected ratings data from a small sampling test. Your task is to systematically analyze and clean the ratings data to identify top-performing flavors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nimport numpy as np\n\nmilkshake_ratings_data = [\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 4.5,\n    \"customer_id\": \"CUST001\",\n    \"rating_date\": \"2024-07-05\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": 3.8,\n    \"customer_id\": \"CUST002\",\n    \"rating_date\": \"2024-07-10\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 4.2,\n    \"customer_id\": \"CUST003\",\n    \"rating_date\": \"2024-07-15\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": 3.5,\n    \"customer_id\": \"CUST004\",\n    \"rating_date\": \"2024-07-20\"\n  },\n  {\n    \"flavor\": \"Mocha Bean\",\n    \"rating\": null,\n    \"customer_id\": \"CUST005\",\n    \"rating_date\": \"2024-07-25\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 4.5,\n    \"customer_id\": \"CUST001\",\n    \"rating_date\": \"2024-07-05\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 5,\n    \"customer_id\": \"CUST006\",\n    \"rating_date\": \"2024-08-01\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": 4,\n    \"customer_id\": \"CUST007\",\n    \"rating_date\": \"2024-08-02\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 3.9,\n    \"customer_id\": \"CUST008\",\n    \"rating_date\": \"2024-08-03\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": 4.8,\n    \"customer_id\": \"CUST009\",\n    \"rating_date\": \"2024-10-04\"\n  },\n  {\n    \"flavor\": \"Mocha Bean\",\n    \"rating\": 2.5,\n    \"customer_id\": \"CUST010\",\n    \"rating_date\": \"2024-09-05\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 4.7,\n    \"customer_id\": \"CUST011\",\n    \"rating_date\": \"2024-10-06\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": null,\n    \"customer_id\": \"CUST012\",\n    \"rating_date\": \"2024-10-07\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 4.3,\n    \"customer_id\": \"CUST013\",\n    \"rating_date\": \"2024-10-08\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": 4.9,\n    \"customer_id\": \"CUST014\",\n    \"rating_date\": \"2024-10-09\"\n  },\n  {\n    \"flavor\": \"Mocha Bean\",\n    \"rating\": 3.3,\n    \"customer_id\": \"CUST015\",\n    \"rating_date\": \"2024-08-10\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 1,\n    \"customer_id\": \"CUST016\",\n    \"rating_date\": \"2024-08-11\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": 6,\n    \"customer_id\": \"CUST017\",\n    \"rating_date\": \"2024-08-12\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 3,\n    \"customer_id\": \"CUST018\",\n    \"rating_date\": \"2024-08-13\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": 4.2,\n    \"customer_id\": \"CUST019\",\n    \"rating_date\": \"2024-08-14\"\n  },\n  {\n    \"flavor\": \"Mocha Bean\",\n    \"rating\": 4.1,\n    \"customer_id\": \"CUST020\",\n    \"rating_date\": \"2024-08-15\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 3.7,\n    \"customer_id\": \"CUST021\",\n    \"rating_date\": \"2024-08-16\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": 3.9,\n    \"customer_id\": \"CUST022\",\n    \"rating_date\": \"2024-08-17\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 4.4,\n    \"customer_id\": \"CUST023\",\n    \"rating_date\": \"2024-08-18\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": 3.6,\n    \"customer_id\": \"CUST024\",\n    \"rating_date\": \"2024-08-19\"\n  },\n  {\n    \"flavor\": \"Mocha Bean\",\n    \"rating\": null,\n    \"customer_id\": \"CUST025\",\n    \"rating_date\": \"2024-08-20\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 4.8,\n    \"customer_id\": \"CUST026\",\n    \"rating_date\": \"2024-08-21\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": 4.6,\n    \"customer_id\": \"CUST027\",\n    \"rating_date\": \"2024-08-22\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 4,\n    \"customer_id\": \"CUST028\",\n    \"rating_date\": \"2024-08-23\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": 4.4,\n    \"customer_id\": \"CUST029\",\n    \"rating_date\": \"2024-08-24\"\n  },\n  {\n    \"flavor\": \"Mocha Bean\",\n    \"rating\": 3.2,\n    \"customer_id\": \"CUST030\",\n    \"rating_date\": \"2024-11-25\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 4.9,\n    \"customer_id\": \"CUST031\",\n    \"rating_date\": \"2024-11-26\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": 4.1,\n    \"customer_id\": \"CUST032\",\n    \"rating_date\": \"2024-11-27\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 3.3,\n    \"customer_id\": \"CUST033\",\n    \"rating_date\": \"2024-11-28\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": 3.8,\n    \"customer_id\": \"CUST034\",\n    \"rating_date\": \"2024-11-29\"\n  },\n  {\n    \"flavor\": \"Mocha Bean\",\n    \"rating\": 4,\n    \"customer_id\": \"CUST035\",\n    \"rating_date\": \"2024-11-30\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 4.3,\n    \"customer_id\": \"CUST036\",\n    \"rating_date\": \"2024-12-01\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": null,\n    \"customer_id\": \"CUST037\",\n    \"rating_date\": \"2024-12-02\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 3.7,\n    \"customer_id\": \"CUST038\",\n    \"rating_date\": \"2024-12-03\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": 4.5,\n    \"customer_id\": \"CUST039\",\n    \"rating_date\": \"2024-12-04\"\n  },\n  {\n    \"flavor\": \"Mocha Bean\",\n    \"rating\": 3.9,\n    \"customer_id\": \"CUST040\",\n    \"rating_date\": \"2024-12-05\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 4.4,\n    \"customer_id\": \"CUST041\",\n    \"rating_date\": \"2024-12-06\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": 3.5,\n    \"customer_id\": \"CUST042\",\n    \"rating_date\": \"2024-12-07\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 4.6,\n    \"customer_id\": \"CUST043\",\n    \"rating_date\": \"2024-12-08\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": 4.2,\n    \"customer_id\": \"CUST044\",\n    \"rating_date\": \"2025-02-09\"\n  },\n  {\n    \"flavor\": \"Mocha Bean\",\n    \"rating\": 3.4,\n    \"customer_id\": \"CUST045\",\n    \"rating_date\": \"2025-02-10\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": null,\n    \"customer_id\": \"CUST046\",\n    \"rating_date\": \"2025-02-11\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": 4,\n    \"customer_id\": \"CUST047\",\n    \"rating_date\": \"2025-02-12\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 4.1,\n    \"customer_id\": \"CUST048\",\n    \"rating_date\": \"2025-02-13\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": 4.3,\n    \"customer_id\": \"CUST049\",\n    \"rating_date\": \"2025-04-14\"\n  },\n  {\n    \"flavor\": \"Mocha Bean\",\n    \"rating\": 3.7,\n    \"customer_id\": \"CUST050\",\n    \"rating_date\": \"2025-04-15\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 4.6,\n    \"customer_id\": \"CUST051\",\n    \"rating_date\": \"2025-04-16\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": 4.3,\n    \"customer_id\": \"CUST052\",\n    \"rating_date\": \"2025-04-17\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 3.8,\n    \"customer_id\": \"CUST053\",\n    \"rating_date\": \"2025-04-18\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": null,\n    \"customer_id\": \"CUST054\",\n    \"rating_date\": \"2025-06-19\"\n  },\n  {\n    \"flavor\": \"Mocha Bean\",\n    \"rating\": 4.7,\n    \"customer_id\": \"CUST055\",\n    \"rating_date\": \"2025-06-20\"\n  },\n  {\n    \"flavor\": \"Classic Chocolate\",\n    \"rating\": 4,\n    \"customer_id\": \"CUST056\",\n    \"rating_date\": \"2025-06-21\"\n  },\n  {\n    \"flavor\": \"Strawberry Swirl\",\n    \"rating\": 4.2,\n    \"customer_id\": \"CUST057\",\n    \"rating_date\": \"2025-06-22\"\n  },\n  {\n    \"flavor\": \"Vanilla Bean\",\n    \"rating\": 3.6,\n    \"customer_id\": \"CUST058\",\n    \"rating_date\": \"2025-06-23\"\n  },\n  {\n    \"flavor\": \"Caramel Delight\",\n    \"rating\": 4,\n    \"customer_id\": \"CUST059\",\n    \"rating_date\": \"2025-06-24\"\n  }\n]\nmilkshake_ratings = pd.DataFrame(milkshake_ratings_data)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1\n\nThere was an error in our data collection process, and we unknowingly introduced duplciate rows into our data. Remove any duplicate entries in the customer ratings data to ensure the accuracy of the analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: milkshake_ratings\n# Please print your final result or dataframe\n\n# Load the CSV file into a DataFrame\nmilkshake_ratings_df = milkshake_ratings.copy()\nprint(milkshake_ratings_df)\nprint()\nprint(milkshake_ratings_df.info())\n\n# We can quickly do this by using .duplicated().sum()\nduplicate_records = milkshake_ratings_df.duplicated().sum()\nprint('The number of duplicate values on the data set is:', duplicate_records)\nprint()\n\n# Identify all duplicate rows, including the first occurrence\nall_duplicate_rows = milkshake_ratings_df[milkshake_ratings_df.duplicated(keep=False)]\nprint('All duplicate rows in the data set are:') ; \nprint(all_duplicate_rows)\nprint()\n\n# Now that we have identified the duplicate rows, we can drop them\nmilkshake_ratings_df = milkshake_ratings_df.drop_duplicates()\nprint(milkshake_ratings_df.info())\nprint()\nprint(\"=\" * 100)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2\n\nFor each milkshake flavor, calculate the average customer rating and append this as a new column to the milkshake_ratings DataFrame. Don't forget to clean the DataFrame first by dropping duplicate values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: milkshake_ratings\n# Please print your final result or dataframe\n\n# Load the CSV file into a DataFrame\nmilkshake_ratings_df = milkshake_ratings.copy()\nprint(milkshake_ratings_df)\nprint()\nprint(milkshake_ratings_df.info())\n\n# We can quickly do this by using .duplicated().sum()\nduplicate_records = milkshake_ratings_df.duplicated().sum()\nprint('The number of duplicate values on the data set is:', duplicate_records)\nprint()\n\n# Identify all duplicate rows, including the first occurrence\nall_duplicate_rows = milkshake_ratings_df[milkshake_ratings_df.duplicated(keep=False)]\nprint('All duplicate rows in the data set are:') ; \nprint(all_duplicate_rows)\nprint()\n\n# Now that we have identified the duplicate rows, we can drop them\nclean_milkshake_ratings_df = milkshake_ratings_df.drop_duplicates()\nprint(\"Answer 1: Cleaned dataframe with no duplicate rows:\")\nprint(clean_milkshake_ratings_df.info())\nprint()\nprint(\"=\" * 100)\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 2 of 3\n# CFor each milkshake flavor, calculate the average customer rating and append this as a new column to the milkshake_ratings DataFrame. Don't forget to clean the DataFrame first by dropping duplicate values.\n\n# Before we work on this question we need to address the null values, we will be dropping them so they dont affect our analysis\nclean_milkshake_ratings_df = clean_milkshake_ratings_df.dropna()\nprint(clean_milkshake_ratings_df.info())\nprint()\nprint(\"=\" * 100)\n\n# Now tat the null values are removed, we can work on this question\n# We need to group the data by flavor and get the average rating for each flavor\nflavor_ratings = clean_milkshake_ratings_df.groupby('flavor').agg({'rating': 'mean'}).round(2).rename(columns={'rating': 'avg_rating'})\nprint(flavor_ratings)\nprint()\nprint(\"=\" * 100)\n\n# Now we just need to append this data to the milkshake_ratings data set\nappend_milkshake_ratings_df = pd.merge(clean_milkshake_ratings_df, flavor_ratings, how='right', on='flavor').sort_values('customer_id').reset_index(drop=True)\nprint(append_milkshake_ratings_df.info())\nprint(\"\\nAnswer 2: Cleaned dataframe with new 'avg_rating' column:\")\nprint(append_milkshake_ratings_df)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3\n\nFor each row in dataset, calculate the difference between that customer's rating and the average rating for the flavor. Don't forget to clean the DataFrame first by dropping duplicate values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: milkshake_ratings\n# Please print your final result or dataframe\n\n# Load the CSV file into a DataFrame\nmilkshake_ratings_df = milkshake_ratings.copy()\nprint(milkshake_ratings_df)\nprint()\nprint(milkshake_ratings_df.info())\n\n# We can quickly do this by using .duplicated().sum()\nduplicate_records = milkshake_ratings_df.duplicated().sum()\nprint('The number of duplicate values on the data set is:', duplicate_records)\nprint()\n\n# Identify all duplicate rows, including the first occurrence\nall_duplicate_rows = milkshake_ratings_df[milkshake_ratings_df.duplicated(keep=False)]\nprint('All duplicate rows in the data set are:') ; \nprint(all_duplicate_rows)\nprint()\n\n# Now that we have identified the duplicate rows, we can drop them\nclean_milkshake_ratings_df = milkshake_ratings_df.drop_duplicates()\nprint(\"Answer 1: Cleaned dataframe with no duplicate rows:\")\nprint(clean_milkshake_ratings_df.info())\nprint()\nprint(\"=\" * 100)\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 2 of 3\n# CFor each milkshake flavor, calculate the average customer rating and append this as a new column to the milkshake_ratings DataFrame. Don't forget to clean the DataFrame first by dropping duplicate values.\n\n# Before we work on this question we need to address the null values, we will be dropping them so they dont affect our analysis\nclean_milkshake_ratings_df = clean_milkshake_ratings_df.dropna()\nprint(clean_milkshake_ratings_df.info())\nprint()\nprint(\"=\" * 100)\n\n# Now tat the null values are removed, we can work on this question\n# We need to group the data by flavor and get the average rating for each flavor\nflavor_ratings = clean_milkshake_ratings_df.groupby('flavor').agg({'rating': 'mean'}).round(2).rename(columns={'rating': 'avg_rating'})\nprint(flavor_ratings)\nprint()\nprint(\"=\" * 100)\n\n# Now we just need to append this data to the milkshake_ratings data set\nappend_milkshake_ratings_df = pd.merge(clean_milkshake_ratings_df, flavor_ratings, how='right', on='flavor').sort_values('customer_id').reset_index(drop=True)\nprint(append_milkshake_ratings_df.info())\nprint(\"\\nAnswer 2: Cleaned dataframe with new 'avg_rating' column:\")\nprint(append_milkshake_ratings_df)\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 3 of 3\n# For each row in the dataset, calculate the difference between that customer's rating and the average rating for the flavor. Don't forget to clean the DataFrame first by dropping duplicate values.\n\n# Calculating and creating a new column with the difference between the rating and the average rating\nappend_milkshake_ratings_df['difference'] = append_milkshake_ratings_df['rating'] - append_milkshake_ratings_df['avg_rating']\nprint(append_milkshake_ratings_df)\nprint()\nprint(\"=\" * 150)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Made with ❤️ by [Interview Master](https://www.interviewmaster.ai)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3",
      "mimetype": "text/x-python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}