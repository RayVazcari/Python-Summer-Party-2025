{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 9: Instagram Stories Daily User Creation Patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You are a Product Analyst on the Instagram Stories team investigating story creation patterns. The team wants to understand the distribution of stories created by users daily. You will analyze user storytelling behavior to optimize engagement strategies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nimport numpy as np\n\nstories_data_data = [\n  {\n    \"user_id\": \"user_001\",\n    \"story_date\": \"2024-07-03\",\n    \"story_count\": 3\n  },\n  {\n    \"user_id\": \"user_001\",\n    \"story_date\": \"2024-07-03\",\n    \"story_count\": 3\n  },\n  {\n    \"user_id\": \"user_001\",\n    \"story_date\": \"2024-08-15\",\n    \"story_count\": 5\n  },\n  {\n    \"user_id\": \"user_001\",\n    \"story_date\": \"2024-09-10\",\n    \"story_count\": 0\n  },\n  {\n    \"user_id\": \"user_001\",\n    \"story_date\": \"2024-10-05\",\n    \"story_count\": 20\n  },\n  {\n    \"user_id\": \"user_001\",\n    \"story_date\": \"07/15/2024\",\n    \"story_count\": 2\n  },\n  {\n    \"user_id\": \"user_002\",\n    \"story_date\": \"2024-07-03\",\n    \"story_count\": 4\n  },\n  {\n    \"user_id\": \" user_002\",\n    \"story_date\": \"2024-07-04\",\n    \"story_count\": 3\n  },\n  {\n    \"user_id\": \"user_002\",\n    \"story_date\": null,\n    \"story_count\": 6\n  },\n  {\n    \"user_id\": \"user_002\",\n    \"story_date\": \"2024-12-25\",\n    \"story_count\": 1\n  },\n  {\n    \"user_id\": \"user_002\",\n    \"story_date\": \"2025-01-15\",\n    \"story_count\": 7\n  },\n  {\n    \"user_id\": \"user_002\",\n    \"story_date\": \"2025-06-29\",\n    \"story_count\": 10\n  },\n  {\n    \"user_id\": \"user_003\",\n    \"story_date\": \"2024-07-10\",\n    \"story_count\": 2\n  },\n  {\n    \"user_id\": \"user_003\",\n    \"story_date\": \"2024-08-20\",\n    \"story_count\": 8\n  },\n  {\n    \"user_id\": \"user_003\",\n    \"story_date\": \"2024-08-20\",\n    \"story_count\": 8\n  },\n  {\n    \"user_id\": \"user_003\",\n    \"story_date\": \"2025-03-11\",\n    \"story_count\": 5\n  },\n  {\n    \"user_id\": null,\n    \"story_date\": \"2025-03-12\",\n    \"story_count\": 3\n  },\n  {\n    \"user_id\": \"USER_003\",\n    \"story_date\": \"2025-04-01\",\n    \"story_count\": 4\n  },\n  {\n    \"user_id\": \"user_004\",\n    \"story_date\": \"2024-07-15\",\n    \"story_count\": 6\n  },\n  {\n    \"user_id\": \"user_004\",\n    \"story_date\": \"2024-09-30\",\n    \"story_count\": 7\n  },\n  {\n    \"user_id\": \"user_004\",\n    \"story_date\": \"2024/10/10\",\n    \"story_count\": 4\n  },\n  {\n    \"user_id\": \"user_004\",\n    \"story_date\": \"2024-11-11\",\n    \"story_count\": 3\n  },\n  {\n    \"user_id\": \"user_004\",\n    \"story_date\": \"2025-02-28\",\n    \"story_count\": 12\n  },\n  {\n    \"user_id\": \"user_004\",\n    \"story_date\": \"2025-03-01\",\n    \"story_count\": 0\n  },\n  {\n    \"user_id\": \"user_005\",\n    \"story_date\": \"2024-08-01\",\n    \"story_count\": 1\n  },\n  {\n    \"user_id\": \"user_005\",\n    \"story_date\": \"2024-08-02\",\n    \"story_count\": 2\n  },\n  {\n    \"user_id\": \"user_005\",\n    \"story_date\": \"2024-08-03\",\n    \"story_count\": 3\n  },\n  {\n    \"user_id\": \"user_005\",\n    \"story_date\": \"2024-08-04\",\n    \"story_count\": 4\n  },\n  {\n    \"user_id\": \"user_005\",\n    \"story_date\": \"2024-08-05\",\n    \"story_count\": null\n  },\n  {\n    \"user_id\": \"user_005\",\n    \"story_date\": \"2024-08-06\",\n    \"story_count\": 5\n  },\n  {\n    \"user_id\": \"user_006\",\n    \"story_date\": \"2024-09-01\",\n    \"story_count\": 9\n  },\n  {\n    \"user_id\": \"user_006\",\n    \"story_date\": \"2024-09-02\",\n    \"story_count\": 10\n  },\n  {\n    \"user_id\": \"user_006\",\n    \"story_date\": \"2024-09-03\",\n    \"story_count\": 9\n  },\n  {\n    \"user_id\": \"user_006\",\n    \"story_date\": \"2024-09-04\",\n    \"story_count\": 50\n  },\n  {\n    \"user_id\": \"user_006\",\n    \"story_date\": \"2024-09-05\",\n    \"story_count\": 8\n  },\n  {\n    \"user_id\": \"user_006\",\n    \"story_date\": null,\n    \"story_count\": 7\n  },\n  {\n    \"user_id\": \"user_007\",\n    \"story_date\": \"2024-10-10\",\n    \"story_count\": 4\n  },\n  {\n    \"user_id\": \"user_007\",\n    \"story_date\": \"2024-10-11\",\n    \"story_count\": 4\n  },\n  {\n    \"user_id\": \"user_007\",\n    \"story_date\": \"2024-10-12\",\n    \"story_count\": 4\n  },\n  {\n    \"user_id\": \"user_007\",\n    \"story_date\": \"2024-10-13\",\n    \"story_count\": 3\n  },\n  {\n    \"user_id\": \"user_007\",\n    \"story_date\": \"2024-10-14\",\n    \"story_count\": 2\n  },\n  {\n    \"user_id\": \"user_007\",\n    \"story_date\": \"2024-10-15\",\n    \"story_count\": 1\n  },\n  {\n    \"user_id\": \"user_008\",\n    \"story_date\": \"2025-01-01\",\n    \"story_count\": 11\n  },\n  {\n    \"user_id\": \"user_008\",\n    \"story_date\": \"2025-01-02\",\n    \"story_count\": 12\n  },\n  {\n    \"user_id\": \"user_008\",\n    \"story_date\": \"2025-01-03\",\n    \"story_count\": 13\n  },\n  {\n    \"user_id\": \"user_008\",\n    \"story_date\": \"2025-01-04\",\n    \"story_count\": 14\n  },\n  {\n    \"user_id\": \"user_008\",\n    \"story_date\": \"2025-01-05\",\n    \"story_count\": 15\n  },\n  {\n    \"user_id\": \"user_008\",\n    \"story_date\": \"2025-01-06\",\n    \"story_count\": 0\n  },\n  {\n    \"user_id\": \"user_009\",\n    \"story_date\": \"2024-12-01\",\n    \"story_count\": 1\n  },\n  {\n    \"user_id\": \"user_009\",\n    \"story_date\": \"2024-12-02\",\n    \"story_count\": 2\n  },\n  {\n    \"user_id\": \"user_009\",\n    \"story_date\": \"2024-12-03\",\n    \"story_count\": 3\n  },\n  {\n    \"user_id\": \"user_009\",\n    \"story_date\": \"2024-12-04\",\n    \"story_count\": 4\n  },\n  {\n    \"user_id\": \"user_009\",\n    \"story_date\": \"2024-12-05\",\n    \"story_count\": 5\n  },\n  {\n    \"user_id\": \"user_009\",\n    \"story_date\": \"invalid_date\",\n    \"story_count\": 6\n  },\n  {\n    \"user_id\": \"user_010\",\n    \"story_date\": \"2025-03-15\",\n    \"story_count\": 7\n  },\n  {\n    \"user_id\": \"user_010\",\n    \"story_date\": \"2025-03-16\",\n    \"story_count\": 8\n  },\n  {\n    \"user_id\": \"user_010\",\n    \"story_date\": \"2025-03-17\",\n    \"story_count\": 9\n  },\n  {\n    \"user_id\": \"user_010\",\n    \"story_date\": \"2025-03-18\",\n    \"story_count\": 10\n  },\n  {\n    \"user_id\": \"user_010\",\n    \"story_date\": \"2025-03-19\",\n    \"story_count\": 11\n  },\n  {\n    \"user_id\": \"user_010\",\n    \"story_date\": \"2025-03-20\",\n    \"story_count\": 12\n  }\n]\nstories_data = pd.DataFrame(stories_data_data)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1\n\nTake a look at the data in the story_date column. Correct any data type inconsistencies in that column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: stories_data\n# Please print your final result or dataframe\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 1 of 3 \n# Take a look at the data in the `story_date column`. Correct any data type inconsistencies in that column.\n\n# Load the CSV file into a DataFrame and display it\nstories_df = stories_data.copy()\nprint(stories_df)\nprint(\"=\" * 150)\nprint()\n\n# We can see that there are a total of 60 rows and all three columns have missing values.\n# But first lets change the story_date column to datetime format\nstories_df['story_date'] = pd.to_datetime(stories_df['story_date'], format='%Y-%m-%d')\nprint(stories_df.info())\nprint(\"=\" * 150)\nprint()\n\n# Answer to Question 1: The number of missing values on \"story_date\" column of the data set is:\nsd_missing_values = stories_df[\"story_date\"].isnull().sum()\nprint('The number of missing values on \"story_date\" column of the data set is:', sd_missing_values)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2\n\nCalculate the 25th, 50th, and 75th percentiles of the number of stories created per user per day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: stories_data\n# Please print your final result or dataframe\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 1 of 3 \n# Take a look at the data in the `story_date column`. Correct any data type inconsistencies in that column.\n\n# Load the CSV file into a DataFrame and display it\nstories_df = stories_data.copy()\nprint(stories_df)\nprint(\"=\" * 150)\nprint()\n\n# We can see that there are a total of 60 rows and all three columns have missing values.\n# But first lets change the story_date column to datetime format\nstories_df['story_date'] = pd.to_datetime(stories_df['story_date'], format='%Y-%m-%d')\nprint(stories_df.info())\nprint(\"=\" * 150)\nprint()\n\n# Answer to Question 1: The number of missing values on \"story_date\" column of the data set is:\nsd_missing_values = stories_df[\"story_date\"].isnull().sum()\nprint('The number of missing values on \"story_date\" column of the data set is:', sd_missing_values)\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 2 of 3\n# Calculate the 25th, 50th, and 75th percentiles of the number of stories created per user per day.\n\n# Printing the dataframe to see the data\nprint(stories_df)\n\n# Normalizing and cleaning the data\nstories_df['user_id'] = stories_df['user_id'].str.lower()\nstories_df['user_id'] = stories_df['user_id'].str.lower().str.strip()\nprint(stories_df['user_id'].unique())\n\n# Keep rows we can measure on (drop missing user_id or date for this metric)\nclean = stories_df.dropna(subset=['user_id', 'story_date']).copy()\n\n# Make sure story_count is numeric (and treat NaN as 0 stories)\nclean['story_count'] = pd.to_numeric(clean['story_count'], errors='coerce').fillna(0)\nprint(clean.info())\nprint(clean)\n\n# We can start by doing a groupby operation on user_id and story_date to count the number of stories created by each user on each day\nstories_per_user_per_day = clean.groupby(['user_id', 'story_date']).agg(total_story_count = ('story_count', 'sum')).reset_index().sort_values(by=['user_id', 'story_date'], ascending=[True, True])\nprint(stories_per_user_per_day)\n\n# Now we can calculate the 25th, 50th, and 75th percentiles of the number of stories created per user per day\npercentiles = stories_per_user_per_day['total_story_count'].quantile([0.25, 0.5, 0.75])\npercentiles.index = ['25th', '50th', '75th']\nprint(\"\\nThe 25th, 50th, and 75th percentiles of the number of stories created per user per day are:\")\nprint(percentiles)\n\nper_user_percentiles = (\n    stories_per_user_per_day\n    .groupby('user_id')['total_story_count']\n    .quantile([0.25, 0.5, 0.75])\n    .unstack()              # columns: 0.25, 0.5, 0.75\n    .rename(columns={0.25:'p25', 0.5:'p50', 0.75:'p75'})\n    .reset_index()\n)\nper_user_percentiles.head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3\n\nWhat percentage of users have had at least one day, where they posted more than 10 stories on that day?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: stories_data\n# Please print your final result or dataframe\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 1 of 3 \n# Take a look at the data in the `story_date column`. Correct any data type inconsistencies in that column.\n\n# Load the CSV file into a DataFrame and display it\nstories_df = stories_data.copy()\nprint(stories_df)\nprint(\"=\" * 150)\nprint()\n\n# We can see that there are a total of 60 rows and all three columns have missing values.\n# But first lets change the story_date column to datetime format\nstories_df['story_date'] = pd.to_datetime(stories_df['story_date'], format='%Y-%m-%d')\nprint(stories_df.info())\nprint(\"=\" * 150)\nprint()\n\n# Answer to Question 1: The number of missing values on \"story_date\" column of the data set is:\nsd_missing_values = stories_df[\"story_date\"].isnull().sum()\nprint('The number of missing values on \"story_date\" column of the data set is:', sd_missing_values)\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 2 of 3\n# Calculate the 25th, 50th, and 75th percentiles of the number of stories created per user per day.\n\n# Printing the dataframe to see the data\nprint(stories_df)\nprint(\"=\" * 150)\nprint()\n\n# Normalizing and cleaning the data\nstories_df['user_id'] = stories_df['user_id'].str.lower()\nstories_df['user_id'] = stories_df['user_id'].str.lower().str.strip()\nprint(stories_df['user_id'].unique())\nprint(\"=\" * 150)\nprint()\n\n# Keep rows we can measure on (drop missing user_id or date for this metric)\nclean = stories_df.dropna(subset=['user_id', 'story_date']).copy()\n\n# Make sure story_count is numeric (and treat NaN as 0 stories)\nclean['story_count'] = pd.to_numeric(clean['story_count'], errors='coerce').fillna(0)\nprint(clean.info())\nprint()\nprint(clean)\nprint(\"=\" * 150)\nprint()\n\n# We can start by doing a groupby operation on user_id and story_date to count the number of stories created by each user on each day\nstories_per_user_per_day = clean.groupby(['user_id', 'story_date']).agg(total_story_count = ('story_count', 'sum')).reset_index().sort_values(by=['user_id', 'story_date'], ascending=[True, True])\nprint(stories_per_user_per_day)\nprint(\"=\" * 150)\nprint()\n\n# Now we can calculate the 25th, 50th, and 75th percentiles of the number of stories created per user per day\npercentiles = stories_per_user_per_day['total_story_count'].quantile([0.25, 0.5, 0.75])\npercentiles.index = ['25th', '50th', '75th']\nprint(\"\\nThe 25th, 50th, and 75th percentiles of the number of stories created per user per day are:\")\nprint(percentiles)\nprint(\"=\" * 150)\nprint()\n\nper_user_percentiles = (\n    stories_per_user_per_day\n    .groupby('user_id')['total_story_count']\n    .quantile([0.25, 0.5, 0.75])\n    .unstack()              # columns: 0.25, 0.5, 0.75\n    .rename(columns={0.25:'p25', 0.5:'p50', 0.75:'p75'})\n    .reset_index()\n)\nprint(per_user_percentiles.head())\nprint(\"=\" * 150)\nprint()\n\n################################################################################\nprint()\nprint(\"=\" * 150)\nprint(\"=\" * 150)\nprint()\n################################################################################\n# Question 3 of 3\n\n# Display the dataframe to see the data again\nprint(stories_per_user_per_day)\nprint(\"=\" * 150)\nprint()\n\n# Here we need to first group by user_id and total_story_count to find users who have had at least one day where they posted more than 10 stories on that day\nusers_with_more_than_10_stories = stories_per_user_per_day[stories_per_user_per_day['total_story_count'] > 10]['user_id'].nunique()\nprint('The number of users who have had at least one day where they posted more than 10 stories on that day is:', users_with_more_than_10_stories)\nprint()\n\n# Now we can calculate the percentage of users who have had at least one day where they posted more than 10 stories on that day\ntotal_users = stories_per_user_per_day['user_id'].nunique()\npercentage = (users_with_more_than_10_stories / total_users) * 100\nprint(f\"\\nThe percentage of users who have had at least one day where they posted more than 10 stories on that day is: {percentage:.2f}%\")\nprint(\"=\" * 150)\nprint()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Made with ❤️ by [Interview Master](https://www.interviewmaster.ai)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3",
      "mimetype": "text/x-python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}