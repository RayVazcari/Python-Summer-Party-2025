{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 5: Switch 2 Pre-sales Demand Forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You are a Product Analyst working with the Nintendo Switch 2 pre-sales team to analyze regional pre-order patterns and customer segmentation. Your team needs to understand how different demographics influence pre-sale volumes across regions. You will leverage historical pre-sale transaction data to extract meaningful insights that can guide marketing strategies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nimport numpy as np\n\npre_sale_data_data = [\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C001\",\n    \"pre_order_date\": \"2024-07-02\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Europe\",\n    \"customer_id\": \"C002\",\n    \"pre_order_date\": \"2024-07-03\",\n    \"demographic_group\": \"Casual\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C003\",\n    \"pre_order_date\": \"2024-07-04\",\n    \"demographic_group\": \"Tech Enthusiast\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Latin America\",\n    \"customer_id\": \"C004\",\n    \"pre_order_date\": \"2024-07-05\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 3\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C005\",\n    \"pre_order_date\": \"2024-07-06\",\n    \"demographic_group\": \"Student\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C006\",\n    \"pre_order_date\": \"2024-07-07\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 5\n  },\n  {\n    \"region\": \"Europe\",\n    \"customer_id\": \"C007\",\n    \"pre_order_date\": \"2024-07-08\",\n    \"demographic_group\": null,\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": null,\n    \"customer_id\": \"C008\",\n    \"pre_order_date\": \"2024-07-09\",\n    \"demographic_group\": \"Casual\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C009\",\n    \"pre_order_date\": \"2024-07-10\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 4\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C010\",\n    \"pre_order_date\": \"2024-07-11\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C010\",\n    \"pre_order_date\": \"2024-07-11\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Europe\",\n    \"customer_id\": \"C011\",\n    \"pre_order_date\": \"2024-07-12\",\n    \"demographic_group\": \"Student\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C012\",\n    \"pre_order_date\": \"2024-07-13\",\n    \"demographic_group\": \"Casual\",\n    \"pre_order_quantity\": 3\n  },\n  {\n    \"region\": \"Latin America\",\n    \"customer_id\": \"C013\",\n    \"pre_order_date\": \"2024-07-14\",\n    \"demographic_group\": \"Tech Enthusiast\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C014\",\n    \"pre_order_date\": \"2024-07-15\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 5\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C015\",\n    \"pre_order_date\": \"2024-07-16\",\n    \"demographic_group\": \"Casual\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Europe\",\n    \"customer_id\": \"C016\",\n    \"pre_order_date\": \"2024-07-17\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 4\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C017\",\n    \"pre_order_date\": \"2024-07-18\",\n    \"demographic_group\": \"Student\",\n    \"pre_order_quantity\": 3\n  },\n  {\n    \"region\": \"Latin America\",\n    \"customer_id\": \"C018\",\n    \"pre_order_date\": \"2024-07-19\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C019\",\n    \"pre_order_date\": \"2024-07-20\",\n    \"demographic_group\": \"Tech Enthusiast\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C019\",\n    \"pre_order_date\": \"2024-07-20\",\n    \"demographic_group\": \"Tech Enthusiast\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C020\",\n    \"pre_order_date\": \"2024-07-21\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 3\n  },\n  {\n    \"region\": \"Europe\",\n    \"customer_id\": \"C021\",\n    \"pre_order_date\": \"2024-07-22\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C022\",\n    \"pre_order_date\": \"2024-07-23\",\n    \"demographic_group\": \"Casual\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Latin America\",\n    \"customer_id\": \"C023\",\n    \"pre_order_date\": \"2024-07-24\",\n    \"demographic_group\": \"Student\",\n    \"pre_order_quantity\": 4\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C024\",\n    \"pre_order_date\": \"2024-07-25\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C025\",\n    \"pre_order_date\": \"2024-07-26\",\n    \"demographic_group\": \"Tech Enthusiast\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Europe\",\n    \"customer_id\": \"C026\",\n    \"pre_order_date\": \"2024-07-27\",\n    \"demographic_group\": \"Student\",\n    \"pre_order_quantity\": 5\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C027\",\n    \"pre_order_date\": \"2024-07-28\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Latin America\",\n    \"customer_id\": \"C028\",\n    \"pre_order_date\": \"2024-07-29\",\n    \"demographic_group\": \"Casual\",\n    \"pre_order_quantity\": 3\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C029\",\n    \"pre_order_date\": \"2024-07-30\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C030\",\n    \"pre_order_date\": \"2024-08-01\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C031\",\n    \"pre_order_date\": \"2024-08-02\",\n    \"demographic_group\": null,\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Latin America\",\n    \"customer_id\": \"C032\",\n    \"pre_order_date\": \"2024-08-03\",\n    \"demographic_group\": \"Tech Enthusiast\",\n    \"pre_order_quantity\": 3\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C033\",\n    \"pre_order_date\": \"2024-08-04\",\n    \"demographic_group\": \"Student\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C034\",\n    \"pre_order_date\": \"2024-08-05\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 4\n  },\n  {\n    \"region\": \"Europe\",\n    \"customer_id\": \"C035\",\n    \"pre_order_date\": \"2024-08-06\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C036\",\n    \"pre_order_date\": \"2024-08-07\",\n    \"demographic_group\": \"Casual\",\n    \"pre_order_quantity\": 5\n  },\n  {\n    \"region\": \"Latin America\",\n    \"customer_id\": \"C037\",\n    \"pre_order_date\": \"2024-08-08\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C038\",\n    \"pre_order_date\": \"2024-08-09\",\n    \"demographic_group\": \"Tech Enthusiast\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C039\",\n    \"pre_order_date\": \"2024-08-10\",\n    \"demographic_group\": \"Student\",\n    \"pre_order_quantity\": 10\n  },\n  {\n    \"region\": \"Europe\",\n    \"customer_id\": \"C040\",\n    \"pre_order_date\": \"2024-08-11\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 3\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C041\",\n    \"pre_order_date\": \"2024-08-12\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Latin America\",\n    \"customer_id\": \"C042\",\n    \"pre_order_date\": \"2024-08-13\",\n    \"demographic_group\": \"Casual\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C043\",\n    \"pre_order_date\": \"2024-08-14\",\n    \"demographic_group\": \"Student\",\n    \"pre_order_quantity\": 5\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C044\",\n    \"pre_order_date\": \"2024-08-15\",\n    \"demographic_group\": \"Tech Enthusiast\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Europe\",\n    \"customer_id\": \"C045\",\n    \"pre_order_date\": \"2024-08-16\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C046\",\n    \"pre_order_date\": \"2024-08-17\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 3\n  },\n  {\n    \"region\": \"Latin America\",\n    \"customer_id\": \"C047\",\n    \"pre_order_date\": \"2024-08-18\",\n    \"demographic_group\": \"Casual\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C048\",\n    \"pre_order_date\": \"2024-08-19\",\n    \"demographic_group\": null,\n    \"pre_order_quantity\": 4\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C049\",\n    \"pre_order_date\": \"2024-08-20\",\n    \"demographic_group\": \"Student\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Europe\",\n    \"customer_id\": \"C050\",\n    \"pre_order_date\": \"2024-08-21\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C051\",\n    \"pre_order_date\": \"2024-08-22\",\n    \"demographic_group\": \"Casual\",\n    \"pre_order_quantity\": 3\n  },\n  {\n    \"region\": \"Latin America\",\n    \"customer_id\": \"C052\",\n    \"pre_order_date\": \"2024-08-23\",\n    \"demographic_group\": \"Tech Enthusiast\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C053\",\n    \"pre_order_date\": \"2024-08-24\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"North America\",\n    \"customer_id\": \"C054\",\n    \"pre_order_date\": \"2024-08-25\",\n    \"demographic_group\": \"Gamer\",\n    \"pre_order_quantity\": 1\n  },\n  {\n    \"region\": \"Europe\",\n    \"customer_id\": \"C055\",\n    \"pre_order_date\": \"2024-08-26\",\n    \"demographic_group\": \"Casual\",\n    \"pre_order_quantity\": 2\n  },\n  {\n    \"region\": \"Asia\",\n    \"customer_id\": \"C056\",\n    \"pre_order_date\": \"2024-08-27\",\n    \"demographic_group\": \"Student\",\n    \"pre_order_quantity\": 3\n  },\n  {\n    \"region\": \"Latin America\",\n    \"customer_id\": \"C057\",\n    \"pre_order_date\": \"2024-08-28\",\n    \"demographic_group\": \"Family\",\n    \"pre_order_quantity\": 4\n  },\n  {\n    \"region\": \"Oceania\",\n    \"customer_id\": \"C058\",\n    \"pre_order_date\": \"2024-08-29\",\n    \"demographic_group\": \"Tech Enthusiast\",\n    \"pre_order_quantity\": 1\n  }\n]\npre_sale_data = pd.DataFrame(pre_sale_data_data)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1\n\nWhat percentage of records have missing values in at least one column? Handle the missing values, so that we have a cleaned dataset to work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Note: pandas and numpy are already imported as pd and np\n# The following tables are loaded as pandas DataFrames with the same names: pre_sale_data\n# Please print your final result or dataframe\n\n# Creating a copy of the pre-sale data to avoid modifying the original dataset\ndata = pre_sale_data\nns2_psd_df = data.copy()\n\nns2_psd_df\n\n# Getting initial data info\nns2_psd_df.info()\n\n# Finding out how many records have missing values in at least one column\nmissing_values = ns2_psd_df.isnull().sum()\nprint(missing_values)\n\n# Calculating the percentage of missing values\npercent_missing_values = ((missing_values * 100) / len(ns2_psd_df)).round(2)\nprint(percent_missing_values)\n\npercent_rows_with_missing = (ns2_psd_df.isnull().any(axis=1).mean() * 100).round(2)\nprint(percent_rows_with_missing)\n\nduplicate_records = ns2_psd_df.duplicated().sum()\nprint(duplicate_records)\n\n# Identify all duplicate rows, including the first occurrence\nall_duplicate_rows = ns2_psd_df[ns2_psd_df.duplicated(keep=False)]\n# Display all duplicate rows\nprint(all_duplicate_rows)\n\n# Handling missing values\n# Since the missing values are objects, I will use the Mode to fill them\nClean_psd_df = ns2_psd_df.fillna(\n    {\n        \"region\": ns2_psd_df[\"region\"].mode()[0],\n        \"demographic_group\": ns2_psd_df[\"demographic_group\"].mode()[0],\n    }\n)\nClean_psd_df.info()\n\n\n# Printing the answer for question 1\nprint(\"The number of missing values in the data set are:\")\nprint(missing_values)\nprint()\n\nprint(\"The percentage of records with missing values in the data set are:\")\nprint(percent_missing_values)\nprint()\n\nprint(\n    \"The percentage of rows with at least one missing value in the data set is\",\n    percent_rows_with_missing,\n), \"%\"\nprint()\n\nprint(\"The count of duplicate records in the data set are:\")\nprint(duplicate_records)\nprint()\n\nprint(\"Clean version of the data set with handled missing values:\")\nprint(duplicate_records)\nprint(Clean_psd_df)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2\n\nUsing the cleaned data, calculate the total pre-sale orders per month for each region and demographic group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Creating a copy of the pre-sale data to avoid modifying the original dataset\ndata = pre_sale_data\nns2_psd_df = data.copy()\n\nprint(ns2_psd_df)\nprint(\"-\" * 100)\nprint()\n\n# Getting initial data info\nns2_psd_df.info()\nprint(\"-\" * 100)\nprint()\n\n# Finding out how many records have missing values in at least one column\nmissing_values = ns2_psd_df.isnull().sum()\nprint(missing_values)\nprint(\"-\" * 100)\nprint()\n\n# Calculating the percentage of missing values per row\npercent_missing_values = ((missing_values * 100) / len(ns2_psd_df)).round(2)\nprint(percent_missing_values)\nprint(\"-\" * 100)\nprint()\n\n# Calculating the percentage of rows with missing values\npercent_rows_with_missing = (ns2_psd_df.isnull().any(axis=1).mean() * 100).round(2)\nprint(percent_rows_with_missing)\nprint(\"-\" * 100)\nprint()\n\n# Calculating the complete duplicate records\nduplicate_records = ns2_psd_df.duplicated().sum()\nprint(\"The number of duplicate values on the data set is:\", duplicate_records)\nprint(\"-\" * 100)\nprint()\n\n# Identify all duplicate rows, including the first occurrence\nall_duplicate_rows = ns2_psd_df[ns2_psd_df.duplicated(keep=False)]\n# Display all duplicate rows\nprint(all_duplicate_rows)\nprint(\"-\" * 100)\nprint()\n\n# Handling missing values\n# Since the missing values are objects, I will use the Mode to fill them\nregion_mode = ns2_psd_df[\"region\"].mode()[0]\ndemographic_group_mode = ns2_psd_df[\"demographic_group\"].mode()[0]\n\nprint(\"Region Mode:\", region_mode)\nprint(\"Demographic Group Mode:\", demographic_group_mode)\nprint(\"-\" * 100)\nprint()\n\nClean_psd_df = ns2_psd_df.fillna(\n    {\n        \"region\": region_mode,\n        \"demographic_group\": demographic_group_mode,\n    }\n)\nprint(Clean_psd_df.info())\nprint(\"-\" * 100)\nprint()\n\n# Printing the answer for question 1\nprint(\"The number of missing values in the data set are:\")\nprint(missing_values)\nprint()\n\nprint(\"The percentage of records with missing values in the data set are:\")\nprint(percent_missing_values)\nprint()\n\nprint(\n    \"The percentage of rows with at least one missing value in the data set is\",\n    percent_rows_with_missing,\n), \"%\"\nprint()\n\nprint(\"The count of duplicate records in the data set are:\")\nprint(duplicate_records)\nprint()\n\nprint(\"Clean version of the data set with handled missing values:\")\nprint(Clean_psd_df)\n\nprint(Clean_psd_df.info())\nprint(\"-\" * 100)\nprint()\n\n# We can see that \"pre_order_date has been turned into an object instead of its original datetime format.\n# We will transform it back for further analysis\nClean_psd_df[\"pre_order_date\"] = pd.to_datetime(Clean_psd_df[\"pre_order_date\"], format=\"%Y-%m-%d\")\nprint(Clean_psd_df.info())\nprint(\"-\" * 100)\nprint()\n\n#We first need to group the data by month \nmonth_grouper = pd.Grouper(key=\"pre_order_date\", freq=\"M\")\nprint(month_grouper)\nprint(\"-\" * 100)\nprint()\n\n# Answer\nGrouping_df = (\n    Clean_psd_df.groupby(\n        [month_grouper, \"region\", \"demographic_group\"], as_index=False)\n    .agg(total_orders=(\"pre_order_quantity\", \"sum\"))\n    .sort_values(by=[\"pre_order_date\", \"region\", \"demographic_group\"])\n)\nprint(Grouping_df)\nprint(\"-\" * 100)\nprint()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3\n\nPredict the total pre-sales quantity for each region for September 2024. Assume that growth rate from August to September, is the same as the growth rate from July to August in each region."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Creating a copy of the pre-sale data to avoid modifying the original dataset\ndata = pre_sale_data\nns2_psd_df = data.copy()\n\nprint(ns2_psd_df)\nprint(\"-\" * 100)\nprint()\n\n# Getting initial data info\nns2_psd_df.info()\nprint(\"-\" * 100)\nprint()\n\n# Finding out how many records have missing values in at least one column\nmissing_values = ns2_psd_df.isnull().sum()\nprint(missing_values)\nprint(\"-\" * 100)\nprint()\n\n# Calculating the percentage of missing values per row\npercent_missing_values = ((missing_values * 100) / len(ns2_psd_df)).round(2)\nprint(percent_missing_values)\nprint(\"-\" * 100)\nprint()\n\n# Calculating the percentage of rows with missing values\npercent_rows_with_missing = (ns2_psd_df.isnull().any(axis=1).mean() * 100).round(2)\nprint(percent_rows_with_missing)\nprint(\"-\" * 100)\nprint()\n\n# Calculating the complete duplicate records\nduplicate_records = ns2_psd_df.duplicated().sum()\nprint(\"The number of duplicate values on the data set is:\", duplicate_records)\nprint(\"-\" * 100)\nprint()\n\n# Identify all duplicate rows, including the first occurrence\nall_duplicate_rows = ns2_psd_df[ns2_psd_df.duplicated(keep=False)]\n# Display all duplicate rows\nprint(all_duplicate_rows)\nprint(\"-\" * 100)\nprint()\n\n# Handling missing values\n# Since the missing values are objects, I will use the Mode to fill them\nregion_mode = ns2_psd_df[\"region\"].mode()[0]\ndemographic_group_mode = ns2_psd_df[\"demographic_group\"].mode()[0]\n\nprint(\"Region Mode:\", region_mode)\nprint(\"Demographic Group Mode:\", demographic_group_mode)\nprint(\"-\" * 100)\nprint()\n\nClean_psd_df = ns2_psd_df.fillna(\n    {\n        \"region\": region_mode,\n        \"demographic_group\": demographic_group_mode,\n    }\n)\nprint(Clean_psd_df.info())\nprint(\"-\" * 100)\nprint()\n\n# Printing the answer for question 1\nprint(\"The number of missing values in the data set are:\")\nprint(missing_values)\nprint()\n\nprint(\"The percentage of records with missing values in the data set are:\")\nprint(percent_missing_values)\nprint()\n\nprint(\n    \"The percentage of rows with at least one missing value in the data set is\",\n    percent_rows_with_missing,\n), \"%\"\nprint()\n\nprint(\"The count of duplicate records in the data set are:\")\nprint(duplicate_records)\nprint()\n\nprint(\"Clean version of the data set with handled missing values:\")\nprint(Clean_psd_df)\n\n#####################################################################\n\nprint(Clean_psd_df.info())\nprint(\"-\" * 100)\nprint()\n\n# We can see that \"pre_order_date has been turned into an object instead of its original datetime format.\n# We will transform it back for further analysis\nClean_psd_df[\"pre_order_date\"] = pd.to_datetime(Clean_psd_df[\"pre_order_date\"], format=\"%Y-%m-%d\")\nprint(Clean_psd_df.info())\nprint(\"-\" * 100)\nprint()\n\n#We first need to group the data by month \nmonth_grouper = pd.Grouper(key=\"pre_order_date\", freq=\"M\")\nprint(month_grouper)\nprint(\"-\" * 100)\nprint()\n\n# Answer\nGrouping_df = (\n    Clean_psd_df.groupby(\n        [month_grouper, \"region\", \"demographic_group\"], as_index=False)\n    .agg(total_orders=(\"pre_order_quantity\", \"sum\"))\n    .sort_values(by=[\"pre_order_date\", \"region\", \"demographic_group\"])\n)\nprint(Grouping_df)\nprint(\"-\" * 100)\nprint()\n\n################################################################\nprint(Clean_psd_df.info())\nprint()\n\n#To answer this question a bit more efficiently we will create a month column so we can easily filter the data\nClean_psd_df[\"pre_order_year\"] = Clean_psd_df[\"pre_order_date\"].dt.year\nClean_psd_df[\"pre_order_month\"] = Clean_psd_df[\"pre_order_date\"].dt.month\nprint(Clean_psd_df)\nprint(\"-\" * 100)\nprint()\n\nGrouping_df = (\n    Clean_psd_df.groupby(\n        [\"pre_order_month\", \"region\", \"demographic_group\"], as_index=False)\n    .agg(total_orders=(\"pre_order_quantity\", \"sum\"))\n    .sort_values(by=[\"pre_order_month\", \"region\", \"demographic_group\"])\n)\nprint(Grouping_df)\nprint(\"-\" * 100)\nprint()\n\nnew_grouping = Grouping_df.groupby(\n        [\"pre_order_month\", \"region\"])[\"total_orders\"].sum().reset_index()\nprint(new_grouping)\nprint(\"-\" * 100)\nprint()\n\nPivot_df = new_grouping.pivot(index= 'region', columns='pre_order_month', values=['total_orders']).reset_index()\nprint(Pivot_df)\nprint(\"-\" * 100)\nprint()\n\nJulAug_Growth_rate = Pivot_df['total_orders', 8] / Pivot_df['total_orders', 7]  # Growth rate from July to August\nprint(\"Growth rate from July to August:\")\nprint(JulAug_Growth_rate)\nprint()\n\n# Adding the growth rate to the pivot DataFrame\nPivot_df[\"Jul-Aug_Growth_Rate\"] = JulAug_Growth_rate\n\nPivot_df_growth = Pivot_df\nprint(Pivot_df_growth)\nprint(\"-\" * 100)\nprint()\n\nPredicted_September = Pivot_df_growth['total_orders', 8] * Pivot_df_growth['Jul-Aug_Growth_Rate']\nprint(\"Predicted pre-sales quantity for September 2024:\")\nprint(Predicted_September)\n\n#Adding the predicted September values to the DataFrame\nPivot_df_growth[\"September_Predicted_presales\"] = Predicted_September.round(0)\n\nPredicted_September_presales = Pivot_df_growth\nprint(\"Predicted pre-sales quantity for September 2024 by region:\")\nprint(Predicted_September_presales)\nprint(\"-\" * 100)\nprint()\n\n\n\nPivot_df.columns = [\n    c if isinstance(c, str) else f\"{c[0]}{c[1]}\"\n    for c in Pivot_df.columns\n]\nprint(Pivot_df.columns)\nprint()\n\nfinal_df = Pivot_df.rename(columns={\n    \"total_orders7\": \"July 2024\",\n    \"total_orders8\": \"August 2024\",\n    \"Jul-Aug_Growth_Rate\": \"growth_rate\",\n    \"September_Predicted_presales\": \"September 2024 (predicted)\"\n})\nprint(final_df)\nprint()\n\n# Answering the final question by selecting the relevant columns\nfinal_df = final_df[[\"region\", \"July 2024\", \"August 2024\", \"growth_rate\", \"September 2024 (predicted)\"]]\nfinal_df"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Made with ❤️ by [Interview Master](https://www.interviewmaster.ai)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3",
      "mimetype": "text/x-python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}