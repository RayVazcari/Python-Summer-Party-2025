{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb45371",
   "metadata": {},
   "source": [
    "Day 7 of Python Summer Party\n",
    "\n",
    "by Interview Master\n",
    "\n",
    "Nike\n",
    "\n",
    "Celebrity Product Drops Sales Performance Analysis\n",
    "\n",
    "You are a Product Analyst working on Nike's marketing performance team. Your team wants to evaluate the effectiveness of celebrity product collaborations by analyzing sales data. You will investigate the performance of celebrity product drops to inform future marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902db91f",
   "metadata": {},
   "source": [
    "Question 1\n",
    "\n",
    "For Q1 2025 (January 1st through March 31st, 2025), can you identify all records of celebrity collaborations from the sales data where the sale_amount is missing? This will help us flag incomplete records that could impact the analysis of Nike's product performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048c363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24857339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sale_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sale_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sale_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "celebrity_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7486d7a1-4053-434f-a008-c7b6c5b308b5",
       "rows": [
        [
         "0",
         "1",
         "2025-01-10",
         "901",
         null,
         "101"
        ],
        [
         "1",
         "2",
         "2025-01-15",
         "901",
         "1500.0",
         "101"
        ],
        [
         "2",
         "3",
         "2025-02-03",
         "902",
         "2000.5",
         "102"
        ],
        [
         "3",
         "4",
         "2025-03-12",
         "903",
         "2500.75",
         "103"
        ],
        [
         "4",
         "5",
         "2025-03-20",
         "904",
         null,
         "104"
        ],
        [
         "5",
         "6",
         "2025-02-28",
         "901",
         "1000.0",
         "101"
        ],
        [
         "6",
         "7",
         "2025-03-25",
         "902",
         "300.0",
         "102"
        ],
        [
         "7",
         "8",
         "2025-03-30",
         "905",
         "1800.0",
         "105"
        ],
        [
         "8",
         "9",
         "2025-01-20",
         "903",
         "1200.0",
         "103"
        ],
        [
         "9",
         "10",
         "2025-02-05",
         "906",
         "500.0",
         "106"
        ],
        [
         "10",
         "11",
         "2025-03-01",
         "907",
         "2200.0",
         "107"
        ],
        [
         "11",
         "12",
         "2025-02-15",
         "908",
         "1300.0",
         "101"
        ],
        [
         "12",
         "13",
         "2025-03-15",
         "909",
         null,
         "102"
        ],
        [
         "13",
         "14",
         "2025-01-25",
         "910",
         "900.0",
         "108"
        ],
        [
         "14",
         "15",
         "2025-02-20",
         "905",
         "700.0",
         "105"
        ],
        [
         "15",
         "16",
         "2025-03-28",
         "902",
         "1500.0",
         "102"
        ],
        [
         "16",
         "17",
         "2024-11-15",
         "901",
         "800.0",
         "101"
        ],
        [
         "17",
         "18",
         "2024-07-30",
         "902",
         "1000.0",
         "102"
        ],
        [
         "18",
         "19",
         "2025-04-10",
         "905",
         "2000.0",
         "105"
        ],
        [
         "19",
         "20",
         "2024-09-05",
         "903",
         "1100.0",
         "103"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_id</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>product_id</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>celebrity_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-10</td>\n",
       "      <td>901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>901</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-02-03</td>\n",
       "      <td>902</td>\n",
       "      <td>2000.50</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>903</td>\n",
       "      <td>2500.75</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-03-20</td>\n",
       "      <td>904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>901</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>902</td>\n",
       "      <td>300.00</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2025-03-30</td>\n",
       "      <td>905</td>\n",
       "      <td>1800.00</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2025-01-20</td>\n",
       "      <td>903</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2025-02-05</td>\n",
       "      <td>906</td>\n",
       "      <td>500.00</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>907</td>\n",
       "      <td>2200.00</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2025-02-15</td>\n",
       "      <td>908</td>\n",
       "      <td>1300.00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2025-03-15</td>\n",
       "      <td>909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2025-01-25</td>\n",
       "      <td>910</td>\n",
       "      <td>900.00</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>905</td>\n",
       "      <td>700.00</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2025-03-28</td>\n",
       "      <td>902</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-11-15</td>\n",
       "      <td>901</td>\n",
       "      <td>800.00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>902</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>905</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>903</td>\n",
       "      <td>1100.00</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sale_id   sale_date  product_id  sale_amount  celebrity_id\n",
       "0         1  2025-01-10         901          NaN           101\n",
       "1         2  2025-01-15         901      1500.00           101\n",
       "2         3  2025-02-03         902      2000.50           102\n",
       "3         4  2025-03-12         903      2500.75           103\n",
       "4         5  2025-03-20         904          NaN           104\n",
       "5         6  2025-02-28         901      1000.00           101\n",
       "6         7  2025-03-25         902       300.00           102\n",
       "7         8  2025-03-30         905      1800.00           105\n",
       "8         9  2025-01-20         903      1200.00           103\n",
       "9        10  2025-02-05         906       500.00           106\n",
       "10       11  2025-03-01         907      2200.00           107\n",
       "11       12  2025-02-15         908      1300.00           101\n",
       "12       13  2025-03-15         909          NaN           102\n",
       "13       14  2025-01-25         910       900.00           108\n",
       "14       15  2025-02-20         905       700.00           105\n",
       "15       16  2025-03-28         902      1500.00           102\n",
       "16       17  2024-11-15         901       800.00           101\n",
       "17       18  2024-07-30         902      1000.00           102\n",
       "18       19  2025-04-10         905      2000.00           105\n",
       "19       20  2024-09-05         903      1100.00           103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the sales data\n",
    "fct_sales = pd.read_csv('fct_sales.csv')\n",
    "q1_fct_sales_df = fct_sales.copy()\n",
    "display(q1_fct_sales_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e40014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sale_id       20 non-null     int64  \n",
      " 1   sale_date     20 non-null     object \n",
      " 2   product_id    20 non-null     int64  \n",
      " 3   sale_amount   17 non-null     float64\n",
      " 4   celebrity_id  20 non-null     int64  \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 932.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity checks and initial exploration\n",
    "display(q1_fct_sales_df.info())\n",
    "display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806519dd",
   "metadata": {},
   "source": [
    "We can see there are 17 null or \"Missing Values\" Actually it does not seem that they are called \"Null\"\n",
    "Lets start by changing the date to a datetype format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf2c699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   sale_id       20 non-null     int64         \n",
      " 1   sale_date     20 non-null     datetime64[ns]\n",
      " 2   product_id    20 non-null     int64         \n",
      " 3   sale_amount   17 non-null     float64       \n",
      " 4   celebrity_id  20 non-null     int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3)\n",
      "memory usage: 932.0 bytes\n",
      "None\n",
      "\n",
      "   sale_id  sale_date  product_id  sale_amount  celebrity_id\n",
      "0        1 2025-01-10         901          NaN           101\n",
      "1        2 2025-01-15         901      1500.00           101\n",
      "2        3 2025-02-03         902      2000.50           102\n",
      "3        4 2025-03-12         903      2500.75           103\n",
      "4        5 2025-03-20         904          NaN           104\n"
     ]
    }
   ],
   "source": [
    "# First we need to change the sale_date column to datetime format\n",
    "q1_fct_sales_df[\"sale_date\"] = pd.to_datetime(q1_fct_sales_df[\"sale_date\"], format=\"%Y-%m-%d\")\n",
    "print(q1_fct_sales_df.info())\n",
    "print()\n",
    "print(q1_fct_sales_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26351da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sale_id  sale_date  product_id  sale_amount  celebrity_id\n",
      "0        18 2024-07-30         902      1000.00           102\n",
      "1        20 2024-09-05         903      1100.00           103\n",
      "2        17 2024-11-15         901       800.00           101\n",
      "3         1 2025-01-10         901          NaN           101\n",
      "4         2 2025-01-15         901      1500.00           101\n",
      "5         9 2025-01-20         903      1200.00           103\n",
      "6        14 2025-01-25         910       900.00           108\n",
      "7         3 2025-02-03         902      2000.50           102\n",
      "8        10 2025-02-05         906       500.00           106\n",
      "9        12 2025-02-15         908      1300.00           101\n",
      "10       15 2025-02-20         905       700.00           105\n",
      "11        6 2025-02-28         901      1000.00           101\n",
      "12       11 2025-03-01         907      2200.00           107\n",
      "13        4 2025-03-12         903      2500.75           103\n",
      "14       13 2025-03-15         909          NaN           102\n",
      "15        5 2025-03-20         904          NaN           104\n",
      "16        7 2025-03-25         902       300.00           102\n",
      "17       16 2025-03-28         902      1500.00           102\n",
      "18        8 2025-03-30         905      1800.00           105\n",
      "19       19 2025-04-10         905      2000.00           105\n"
     ]
    }
   ],
   "source": [
    "# Now we sort the dataframe by year and month in ascending order for better readability\n",
    "q1_fct_sales_df = q1_fct_sales_df.sort_values(['sale_date'], ascending=True).reset_index(drop=True)\n",
    "print(q1_fct_sales_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eaac674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sale_id  sale_date  product_id  sale_amount  celebrity_id\n",
      "3         1 2025-01-10         901          NaN           101\n",
      "4         2 2025-01-15         901      1500.00           101\n",
      "5         9 2025-01-20         903      1200.00           103\n",
      "6        14 2025-01-25         910       900.00           108\n",
      "7         3 2025-02-03         902      2000.50           102\n",
      "8        10 2025-02-05         906       500.00           106\n",
      "9        12 2025-02-15         908      1300.00           101\n",
      "10       15 2025-02-20         905       700.00           105\n",
      "11        6 2025-02-28         901      1000.00           101\n",
      "12       11 2025-03-01         907      2200.00           107\n",
      "13        4 2025-03-12         903      2500.75           103\n",
      "14       13 2025-03-15         909          NaN           102\n",
      "15        5 2025-03-20         904          NaN           104\n",
      "16        7 2025-03-25         902       300.00           102\n",
      "17       16 2025-03-28         902      1500.00           102\n",
      "18        8 2025-03-30         905      1800.00           105\n"
     ]
    }
   ],
   "source": [
    "# Now we filter the dataframe for Q1 2025 which is January 1st through March 31st, 2025\n",
    "Q1_df = q1_fct_sales_df[(q1_fct_sales_df['sale_date'] >= '2025-01-01') & (q1_fct_sales_df['sale_date'] <= '2025-03-31')]\n",
    "print(Q1_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c046ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sale_id  sale_date  product_id  sale_amount  celebrity_id\n",
      "3         1 2025-01-10         901          NaN           101\n",
      "14       13 2025-03-15         909          NaN           102\n",
      "15        5 2025-03-20         904          NaN           104\n"
     ]
    }
   ],
   "source": [
    "# We can see there are 3 records with missing sale_amount in Q1 2025\n",
    " #Now we select and filter only those records with missing sale_amount\n",
    "Q1_missing_df = Q1_df[Q1_df['sale_amount'].isnull()]\n",
    "print(Q1_missing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43cbcd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 Answer: There are 3 records with missing sale_amount in Q1 2025.\n",
      "These records are:\n",
      "    sale_id  sale_date  product_id  sale_amount  celebrity_id\n",
      "3         1 2025-01-10         901          NaN           101\n",
      "14       13 2025-03-15         909          NaN           102\n",
      "15        5 2025-03-20         904          NaN           104\n"
     ]
    }
   ],
   "source": [
    "# Question 1 Answer: There are 3 records with missing sale_amount in Q1 2025.'\n",
    "print(\"Question 1 Answer: There are\", len(Q1_missing_df), \"records with missing sale_amount in Q1 2025.\");\n",
    "print(\"These records are:\");\n",
    "print(Q1_missing_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3071656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Note: pandas and numpy are already imported as pd and np\n",
    "# # The following tables are loaded as pandas DataFrames with the same names: fct_sales\n",
    "# # Please print your final result or dataframe\n",
    "\n",
    "# # Load the sales data\n",
    "# q1_fct_sales_df = fct_sales.copy()\n",
    "# print(q1_fct_sales_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Sanity checks and initial exploration\n",
    "# print(q1_fct_sales_df.info())\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # First we need to change the sale_date column to datetime format\n",
    "# q1_fct_sales_df[\"sale_date\"] = pd.to_datetime(q1_fct_sales_df[\"sale_date\"], format=\"%Y-%m-%d\")\n",
    "# print(q1_fct_sales_df.info())\n",
    "# print()\n",
    "# print(q1_fct_sales_df.head())\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Now we sort the dataframe by year and month in ascending order for better readability\n",
    "# q1_fct_sales_df = q1_fct_sales_df.sort_values(['sale_date'], ascending=True).reset_index(drop=True)\n",
    "# print(q1_fct_sales_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Now we filter the dataframe for Q1 2025 which is January 1st through March 31st, 2025\n",
    "# Q1_df = q1_fct_sales_df[(q1_fct_sales_df['sale_date'] >= '2025-01-01') & (q1_fct_sales_df['sale_date'] <= '2025-03-31')]\n",
    "# print(Q1_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # We can see there are 3 records with missing sale_amount in Q1 2025\n",
    "#  #Now we select and filter only those records with missing sale_amount\n",
    "# Q1_missing_df = Q1_df[Q1_df['sale_amount'].isnull()]\n",
    "# print(Q1_missing_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Question 1 Answer: There are 3 records with missing sale_amount in Q1 2025.'\n",
    "# print(\"Question 1 Answer: There are\", len(Q1_missing_df), \"records with missing sale_amount in Q1 2025.\");\n",
    "# print(\"These records are:\");\n",
    "# print(Q1_missing_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977dad07",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "\n",
    "For Q1 2025 (January 1st through March 31st, 2025), can you list the unique combinations of celebrity_id and product_id from the sales table? This will ensure that each collaboration is accurately accounted for in the analysis of Nike's marketing performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bf345f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sale_id  sale_date  product_id  sale_amount  celebrity_id\n",
      "3         1 2025-01-10         901          NaN           101\n",
      "4         2 2025-01-15         901      1500.00           101\n",
      "5         9 2025-01-20         903      1200.00           103\n",
      "6        14 2025-01-25         910       900.00           108\n",
      "7         3 2025-02-03         902      2000.50           102\n",
      "8        10 2025-02-05         906       500.00           106\n",
      "9        12 2025-02-15         908      1300.00           101\n",
      "10       15 2025-02-20         905       700.00           105\n",
      "11        6 2025-02-28         901      1000.00           101\n",
      "12       11 2025-03-01         907      2200.00           107\n",
      "13        4 2025-03-12         903      2500.75           103\n",
      "14       13 2025-03-15         909          NaN           102\n",
      "15        5 2025-03-20         904          NaN           104\n",
      "16        7 2025-03-25         902       300.00           102\n",
      "17       16 2025-03-28         902      1500.00           102\n",
      "18        8 2025-03-30         905      1800.00           105\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16 entries, 3 to 18\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   sale_id       16 non-null     int64         \n",
      " 1   sale_date     16 non-null     datetime64[ns]\n",
      " 2   product_id    16 non-null     int64         \n",
      " 3   sale_amount   13 non-null     float64       \n",
      " 4   celebrity_id  16 non-null     int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3)\n",
      "memory usage: 768.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Printing Q1 dataframe and its info for verification\n",
    "print(Q1_df)\n",
    "print(Q1_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb1470c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   celebrity_id  product_id  count\n",
      "0           101         901      3\n",
      "1           101         908      1\n",
      "2           102         902      3\n",
      "3           102         909      1\n",
      "4           103         903      2\n",
      "5           104         904      1\n",
      "6           105         905      2\n",
      "7           106         906      1\n",
      "8           107         907      1\n",
      "9           108         910      1\n"
     ]
    }
   ],
   "source": [
    "# We can use groupby to get the unique combinations of celebrity_id and product_id\n",
    "Q1_unique_combinations = Q1_df.groupby(['celebrity_id', 'product_id']).size().reset_index(name='count')\n",
    "print(Q1_unique_combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e5063b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2 Answer: The following table shows the unique combinations of celebrity_id and product_id in Q1 2025.\n",
      "   celebrity_id  product_id  count\n",
      "0           101         901      3\n",
      "1           101         908      1\n",
      "2           102         902      3\n",
      "3           102         909      1\n",
      "4           103         903      2\n",
      "5           104         904      1\n",
      "6           105         905      2\n",
      "7           106         906      1\n",
      "8           107         907      1\n",
      "9           108         910      1\n"
     ]
    }
   ],
   "source": [
    "# Question 2 Answer: The following table shows the unique combinations of celebrity_id and product_id in Q1 2025.\n",
    "print(\"Question 2 Answer: The following table shows the unique combinations of celebrity_id and product_id in Q1 2025.\")\n",
    "print(Q1_unique_combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85bdafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Note: pandas and numpy are already imported as pd and np\n",
    "# # The following tables are loaded as pandas DataFrames with the same names: fct_sales\n",
    "# # Please print your final result or dataframe\n",
    "\n",
    "# # Load the sales data\n",
    "# q1_fct_sales_df = fct_sales.copy()\n",
    "# print(q1_fct_sales_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Sanity checks and initial exploration\n",
    "# print(q1_fct_sales_df.info())\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # First we need to change the sale_date column to datetime format\n",
    "# q1_fct_sales_df[\"sale_date\"] = pd.to_datetime(q1_fct_sales_df[\"sale_date\"], format=\"%Y-%m-%d\")\n",
    "# print(q1_fct_sales_df.info())\n",
    "# print()\n",
    "# print(q1_fct_sales_df.head())\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Now we sort the dataframe by year and month in ascending order for better readability\n",
    "# q1_fct_sales_df = q1_fct_sales_df.sort_values(['sale_date'], ascending=True).reset_index(drop=True)\n",
    "# print(q1_fct_sales_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Now we filter the dataframe for Q1 2025 which is January 1st through March 31st, 2025\n",
    "# Q1_df = q1_fct_sales_df[(q1_fct_sales_df['sale_date'] >= '2025-01-01') & (q1_fct_sales_df['sale_date'] <= '2025-03-31')]\n",
    "# print(Q1_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # We can see there are 3 records with missing sale_amount in Q1 2025\n",
    "#  #Now we select and filter only those records with missing sale_amount\n",
    "# Q1_missing_df = Q1_df[Q1_df['sale_amount'].isnull()]\n",
    "# print(Q1_missing_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Question 1 Answer: There are 3 records with missing sale_amount in Q1 2025.'\n",
    "# print(\"Question 1 Answer: There are\", len(Q1_missing_df), \"records with missing sale_amount in Q1 2025.\");\n",
    "# print(\"These records are:\");\n",
    "# print(Q1_missing_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "\n",
    "# # ==============================================================================\n",
    "# print()\n",
    "# print(\"=\" * 150)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "# # ==============================================================================\n",
    "\n",
    "# # Printing Q1 dataframe and its info for verification\n",
    "# print(Q1_df)\n",
    "# print(Q1_df.info())\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # We can use groupby to get the unique combinations of celebrity_id and product_id\n",
    "# Q1_unique_combinations = Q1_df.groupby(['celebrity_id', 'product_id']).size().reset_index(name='count')\n",
    "# print(Q1_unique_combinations)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Question 2 Answer: The following table shows the unique combinations of celebrity_id and product_id in Q1 2025.\n",
    "# print(\"Question 2 Answer: The following table shows the unique combinations of celebrity_id and product_id in Q1 2025.\")\n",
    "# print(Q1_unique_combinations)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf5dd71",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "\n",
    "For Q1 2025 (January 1st through March 31st, 2025), can you rank the unique celebrity collaborations based on their total sales amounts and list the top 3 collaborations in descending order? This will help recommend the most successful partnerships for Nike's future product drop strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c4dbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sale_id  sale_date  product_id  sale_amount  celebrity_id\n",
      "3         1 2025-01-10         901          NaN           101\n",
      "4         2 2025-01-15         901      1500.00           101\n",
      "5         9 2025-01-20         903      1200.00           103\n",
      "6        14 2025-01-25         910       900.00           108\n",
      "7         3 2025-02-03         902      2000.50           102\n",
      "8        10 2025-02-05         906       500.00           106\n",
      "9        12 2025-02-15         908      1300.00           101\n",
      "10       15 2025-02-20         905       700.00           105\n",
      "11        6 2025-02-28         901      1000.00           101\n",
      "12       11 2025-03-01         907      2200.00           107\n",
      "13        4 2025-03-12         903      2500.75           103\n",
      "14       13 2025-03-15         909          NaN           102\n",
      "15        5 2025-03-20         904          NaN           104\n",
      "16        7 2025-03-25         902       300.00           102\n",
      "17       16 2025-03-28         902      1500.00           102\n",
      "18        8 2025-03-30         905      1800.00           105\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16 entries, 3 to 18\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   sale_id       16 non-null     int64         \n",
      " 1   sale_date     16 non-null     datetime64[ns]\n",
      " 2   product_id    16 non-null     int64         \n",
      " 3   sale_amount   13 non-null     float64       \n",
      " 4   celebrity_id  16 non-null     int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3)\n",
      "memory usage: 768.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Printing Q1 dataframe and its info for verification\n",
    "print(Q1_df)\n",
    "print(Q1_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92189195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   celebrity_id  product_id  total_sales_volume\n",
      "0           101         901             2500.00\n",
      "1           101         908             1300.00\n",
      "2           102         902             3800.50\n",
      "3           102         909                0.00\n",
      "4           103         903             3700.75\n",
      "5           104         904                0.00\n",
      "6           105         905             2500.00\n",
      "7           106         906              500.00\n",
      "8           107         907             2200.00\n",
      "9           108         910              900.00\n"
     ]
    }
   ],
   "source": [
    "# We can use groupby to get the unique combinations of celebrity_id and product_id\n",
    "Q1_sales_collabs = Q1_df.groupby(['celebrity_id', 'product_id']).agg(total_sales_volume = ('sale_amount', 'sum')).sort_values(by=['celebrity_id', 'product_id']).reset_index()\n",
    "print(Q1_sales_collabs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fd1bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   celebrity_id  product_id  total_sales_volume\n",
      "0           102         902             3800.50\n",
      "1           103         903             3700.75\n",
      "2           105         905             2500.00\n",
      "3           101         901             2500.00\n",
      "4           107         907             2200.00\n",
      "5           101         908             1300.00\n",
      "6           108         910              900.00\n",
      "7           106         906              500.00\n",
      "8           104         904                0.00\n",
      "9           102         909                0.00\n"
     ]
    }
   ],
   "source": [
    "# Now we rank the collaborations based on total sales volume in descending order\n",
    "Q1_ranked_collabs = Q1_sales_collabs.copy()\n",
    "Q1_ranked_collabs = Q1_ranked_collabs.sort_values(by=['total_sales_volume'], ascending=False).reset_index(drop=True)\n",
    "print(Q1_ranked_collabs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fbf998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   celebrity_id  product_id  total_sales_volume\n",
      "0           102         902             3800.50\n",
      "1           103         903             3700.75\n",
      "2           105         905             2500.00\n"
     ]
    }
   ],
   "source": [
    "# We can use .head() to get the top 3 collaborations now that it is ranked\n",
    "top_3_collabs = Q1_ranked_collabs.head(3)\n",
    "print(top_3_collabs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "526c1c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 3 collaborations based on total sales volume in Q1 2025 are:\n",
      "   celebrity_id  product_id  total_sales_volume\n",
      "0           102         902             3800.50\n",
      "1           103         903             3700.75\n",
      "2           105         905             2500.00\n"
     ]
    }
   ],
   "source": [
    "# Answer to Question 3: The top 3 celebrity-product collaborations based on total sales volume in Q1 2025 are shown in the table above.\n",
    "print(\"The top 3 collaborations based on total sales volume in Q1 2025 are:\")\n",
    "print(top_3_collabs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50941961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Note: pandas and numpy are already imported as pd and np\n",
    "# # The following tables are loaded as pandas DataFrames with the same names: fct_sales\n",
    "# # Please print your final result or dataframe\n",
    "\n",
    "# # Question 1\n",
    "\n",
    "# # Load the sales data\n",
    "# q1_fct_sales_df = fct_sales.copy()\n",
    "# print(q1_fct_sales_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Sanity checks and initial exploration\n",
    "# print(q1_fct_sales_df.info())\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # First we need to change the sale_date column to datetime format\n",
    "# q1_fct_sales_df[\"sale_date\"] = pd.to_datetime(q1_fct_sales_df[\"sale_date\"], format=\"%Y-%m-%d\")\n",
    "# print(q1_fct_sales_df.info())\n",
    "# print()\n",
    "# print(q1_fct_sales_df.head())\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Now we sort the dataframe by year and month in ascending order for better readability\n",
    "# q1_fct_sales_df = q1_fct_sales_df.sort_values(['sale_date'], ascending=True).reset_index(drop=True)\n",
    "# print(q1_fct_sales_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Now we filter the dataframe for Q1 2025 which is January 1st through March 31st, 2025\n",
    "# Q1_df = q1_fct_sales_df[(q1_fct_sales_df['sale_date'] >= '2025-01-01') & (q1_fct_sales_df['sale_date'] <= '2025-03-31')]\n",
    "# print(Q1_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # We can see there are 3 records with missing sale_amount in Q1 2025\n",
    "#  #Now we select and filter only those records with missing sale_amount\n",
    "# Q1_missing_df = Q1_df[Q1_df['sale_amount'].isnull()]\n",
    "# print(Q1_missing_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Question 1 Answer: There are 3 records with missing sale_amount in Q1 2025.'\n",
    "# print(\"Question 1 Answer: There are\", len(Q1_missing_df), \"records with missing sale_amount in Q1 2025.\");\n",
    "# print(\"These records are:\");\n",
    "# print(Q1_missing_df)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "\n",
    "# # ==============================================================================\n",
    "# print()\n",
    "# print(\"=\" * 150)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "# # ==============================================================================\n",
    "\n",
    "# #Question 2\n",
    "\n",
    "# # Printing Q1 dataframe and its info for verification\n",
    "# print(Q1_df)\n",
    "# print(Q1_df.info())\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # We can use groupby to get the unique combinations of celebrity_id and product_id\n",
    "# Q1_unique_combinations = Q1_df.groupby(['celebrity_id', 'product_id']).size().reset_index(name='count')\n",
    "# print(Q1_unique_combinations)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Question 2 Answer: The following table shows the unique combinations of celebrity_id and product_id in Q1 2025.\n",
    "# print(\"Question 2 Answer: The following table shows the unique combinations of celebrity_id and product_id in Q1 2025.\")\n",
    "# print(Q1_unique_combinations)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "\n",
    "# # ==============================================================================\n",
    "# print()\n",
    "# print(\"=\" * 150)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "# # ==============================================================================\n",
    "\n",
    "# #Question 3\n",
    "\n",
    "# # Printing Q1 dataframe and its info for verification\n",
    "# print(Q1_df)\n",
    "# print(Q1_df.info())\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # We can use groupby to get the unique combinations of celebrity_id and product_id\n",
    "# Q1_sales_collabs = Q1_df.groupby(['celebrity_id', 'product_id']).agg(total_sales_volume = ('sale_amount', 'sum')).sort_values(by=['celebrity_id', 'product_id']).reset_index()\n",
    "# print(Q1_sales_collabs)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Now we rank the collaborations based on total sales volume in descending order\n",
    "# Q1_ranked_collabs = Q1_sales_collabs.copy()\n",
    "# Q1_ranked_collabs = Q1_ranked_collabs.sort_values(by=['total_sales_volume'], ascending=False).reset_index(drop=True)\n",
    "# print(Q1_ranked_collabs)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # We can use .head() to get the top 3 collaborations now that it is ranked\n",
    "# top_3_collabs = Q1_ranked_collabs.head(3)\n",
    "# print(top_3_collabs)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n",
    "\n",
    "# # Answer to Question 3: The top 3 celebrity-product collaborations based on total sales volume in Q1 2025 are shown in the table above.\n",
    "# print(\"Question 3 Answer: The top 3 collaborations based on total sales volume in Q1 2025 are:\")\n",
    "# print(top_3_collabs)\n",
    "# print(\"=\" * 150)\n",
    "# print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CondaVEnv)",
   "language": "python",
   "name": "condavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
